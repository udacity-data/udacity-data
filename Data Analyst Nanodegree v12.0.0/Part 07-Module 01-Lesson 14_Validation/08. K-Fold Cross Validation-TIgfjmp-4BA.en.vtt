WEBVTT
Kind: captions
Language: en

00:00:00.540 --> 00:00:03.690
So Katie, you told everybody about training and

00:00:03.690 --> 00:00:06.700
test sets, and I hope people exercise it quite a bit.

00:00:06.700 --> 00:00:08.510
Is that correct? &gt;&gt; Yes, that's right.

00:00:08.510 --> 00:00:11.900
&gt;&gt; So now I'm going to talk about something that slightly generalizes this

00:00:11.900 --> 00:00:13.790
called cross validation.

00:00:13.790 --> 00:00:17.360
And to get into cross validation, let's first talk about problems with

00:00:17.360 --> 00:00:20.950
splitting a data set into training and testing data.

00:00:20.950 --> 00:00:22.580
Suppose this is your data.

00:00:22.580 --> 00:00:25.000
By doing what Katie told you,

00:00:25.000 --> 00:00:29.330
you now have to say what fraction of data is testing and what is training.

00:00:29.330 --> 00:00:33.710
And the dilemma you're running into is you like to maximize both of the sets.

00:00:33.710 --> 00:00:36.458
You want to have as many data points in the training sets to

00:00:36.458 --> 00:00:40.241
get the best learning results, and you want the maximum number of data items in

00:00:40.241 --> 00:00:42.500
your test set to get the best validation.

00:00:42.500 --> 00:00:46.230
But obviously, there's an inherent trade-off here, which is every data point you

00:00:46.230 --> 00:00:50.180
take out of the training set into the test is lost for the training set.

00:00:50.180 --> 00:00:52.070
So we had to reset this trade-off.

00:00:52.070 --> 00:00:54.950
And this is where cross validation comes into the picture.

00:00:54.950 --> 00:01:01.540
The basic idea is that you partition the data set into k bins of equal size.

00:01:01.540 --> 00:01:04.700
So example, if you have 200 data points.

00:01:04.700 --> 00:01:06.580
And you have ten bins.

00:01:06.580 --> 00:01:07.430
Very quickly.

00:01:07.430 --> 00:01:09.003
What's the number of data points per bin?

00:01:09.003 --> 00:01:10.391
Quite obviously, it's 20.

00:01:10.391 --> 00:01:14.490
So you will have 20 data points in each of the 10 bins.

00:01:14.490 --> 00:01:15.630
So here's the picture.

00:01:15.630 --> 00:01:19.946
Whereas in the work that Katie showed you, you just pick one of those bins as

00:01:19.946 --> 00:01:22.454
a testing bin and the other then as a training bin.

00:01:22.454 --> 00:01:27.550
In k-fold cross validation, you run k separate learning experiments.

00:01:27.550 --> 00:01:32.380
In each of those, you pick one of those k subsets as your testing set.

00:01:32.380 --> 00:01:36.336
The remaining k minus one bins are put together into the training set,

00:01:36.336 --> 00:01:39.153
then you train your machine learning algorithm and

00:01:39.153 --> 00:01:43.370
just like before, you'll test the performance on the testing set.

00:01:43.370 --> 00:01:46.710
The key thing in cross validation is you run this multiple times.

00:01:46.710 --> 00:01:51.310
In this case ten times, and then you average the ten different testing set

00:01:51.310 --> 00:01:53.731
performances for the ten different hold out sets, so

00:01:53.731 --> 00:01:57.460
you average the test results from those k experiments.

00:01:57.460 --> 00:02:00.430
So obviously, this takes more compute time because you now have to run

00:02:00.430 --> 00:02:02.700
k separate learning experiments, but

00:02:02.700 --> 00:02:05.940
the assessment of the learning algorithm will be more accurate.

00:02:05.940 --> 00:02:08.240
And in a way, you've kind of used all your data for

00:02:08.240 --> 00:02:11.820
training and all your data for testing, which is kind of cool.

00:02:11.820 --> 00:02:13.320
Say we just ask one question.

00:02:13.320 --> 00:02:17.060
Suppose you have a choice to do the static train test methodology that Katie

00:02:17.060 --> 00:02:21.630
told you about, or you do say 10-fold cross validation, C.V., and

00:02:21.630 --> 00:02:24.070
you really care about minimizing training time.

00:02:24.070 --> 00:02:27.700
Minimize run time after training using your machine learning algorithm

00:02:27.700 --> 00:02:30.870
to output past the training time and maximize accuracy.

00:02:30.870 --> 00:02:34.438
In each of these three situations, you might pick either train/test or

00:02:34.438 --> 00:02:36.210
10-fold cross validation.

00:02:36.210 --> 00:02:37.140
Give me your best guess.

00:02:37.140 --> 00:02:38.140
Which one would you pick?

00:02:38.140 --> 00:02:39.760
So for each minimum training time,

00:02:39.760 --> 00:02:41.180
pick one of the two over here on the right side.

