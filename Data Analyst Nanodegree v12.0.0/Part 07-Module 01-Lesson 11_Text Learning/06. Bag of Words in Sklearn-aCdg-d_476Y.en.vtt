WEBVTT
Kind: captions
Language: en

00:00:00.790 --> 00:00:04.160
Now that you're familiar with the Bag of Words representation,

00:00:04.160 --> 00:00:08.182
let's get your hands on the keyboard and have you using it in sklearn.

00:00:08.182 --> 00:00:12.400
In sklearn Bag of Words is called CountVectorizer, presumably because it's

00:00:12.400 --> 00:00:16.520
counting the number of times various words show up in a corpus.

00:00:16.520 --> 00:00:19.450
Now I'm going to walk you through some examples on the interpreter.

00:00:19.450 --> 00:00:20.350
And in the next few videos,

00:00:20.350 --> 00:00:23.930
you get some hands-on experience via programming quizzes.

00:00:23.930 --> 00:00:27.430
I head over to the interpreter and using the online documentation for

00:00:27.430 --> 00:00:30.325
reference, I import the CountVectorizer.

00:00:30.325 --> 00:00:36.430
CountVectorizer lives in the feature_extraction.text part of sklearn.

00:00:37.470 --> 00:00:38.860
She got wrong the first time.

00:00:38.860 --> 00:00:42.670
But I can import it just like any other object in sklearn.

00:00:42.670 --> 00:00:44.010
Then I create my vectorizer.

00:00:44.010 --> 00:00:48.880
And I need to feed it some documents that come in the form of strings.

00:00:48.880 --> 00:00:50.710
I liked Sebastian's example, but

00:00:50.710 --> 00:00:53.980
I think I want to do something that sounds a little bit more like the emails

00:00:53.980 --> 00:00:56.810
that I would actually expect to see in an inbox.

00:00:56.810 --> 00:00:58.570
So we'll make up some strings.

00:00:58.570 --> 00:01:01.940
These aren't really emails, but they kind of sound like them.

00:01:01.940 --> 00:01:04.900
The first thing I need to do to get these into CountVectorizer is I need to

00:01:04.900 --> 00:01:06.610
put them into a list.

00:01:06.610 --> 00:01:08.790
Now I'm going to create the bag-of-words,

00:01:08.790 --> 00:01:13.410
which is what I get when I put this email list into my CountVectorizer.

00:01:13.410 --> 00:01:15.230
And I actually did this a, a little bit wrong.

00:01:15.230 --> 00:01:17.510
There's two steps that I forgot here.

00:01:17.510 --> 00:01:20.920
The first is that I need to fit my data using my Vectorizer.

00:01:20.920 --> 00:01:23.310
The next thing is I need to transform it.

00:01:23.310 --> 00:01:24.480
So first, I'll do the fit.

00:01:24.480 --> 00:01:27.930
This is where it's actually figuring out what all the words in the corpus are,

00:01:27.930 --> 00:01:30.330
all the words in all the emails.

00:01:30.330 --> 00:01:33.820
And assigning say, numbers or list indices to each of them.

00:01:33.820 --> 00:01:36.730
And then the transform is where it actually takes all the words in

00:01:36.730 --> 00:01:41.420
the corpus and figures out how many counts of each word occur.

00:01:41.420 --> 00:01:43.631
My syntax isn't perfect here, but this should work.

00:01:46.314 --> 00:01:49.190
And now to start to understand this, let me print my bag-of-words.

00:01:49.190 --> 00:01:50.680
See what it looks like.

00:01:50.680 --> 00:01:54.740
What I get is a bunch of tuples and integers, and while this looks

00:01:54.740 --> 00:01:58.880
rather opaque, we can actually unpack it in a fairly straightforward way.

00:01:58.880 --> 00:02:01.110
Let's take this row as an example.

00:02:01.110 --> 00:02:04.770
The way to interpret this is that in document number one,

00:02:04.770 --> 00:02:06.780
word number seven occurs one time.

00:02:06.780 --> 00:02:08.490
Now, of course,

00:02:08.490 --> 00:02:12.090
we have to ask what word number seven is in order to interpret this as humans.

00:02:13.270 --> 00:02:14.800
But all of the information is there.

00:02:15.850 --> 00:02:21.270
Similarly, I can see in document number one, word number six occurs three times.

00:02:21.270 --> 00:02:24.060
So just out of curiosity, let's go back up to document number one and

00:02:24.060 --> 00:02:26.990
figure out what we think word number six is.

00:02:26.990 --> 00:02:31.290
So document number one is going to be string two.

00:02:31.290 --> 00:02:33.640
Because the indexing starts at zero.

00:02:33.640 --> 00:02:37.520
And I can see that there is a actually a word that's repeated three times, and

00:02:37.520 --> 00:02:39.450
it's the word great.

00:02:39.450 --> 00:02:41.720
So assuming that that's what word number seven is,

00:02:41.720 --> 00:02:42.820
things are starting to make sense.

00:02:43.940 --> 00:02:46.190
&gt;From looking at the sklearn documentation,

00:02:46.190 --> 00:02:49.750
I see that there's an attribute of the bag-of-words called the vocabulary.

00:02:49.750 --> 00:02:52.630
And this is a way that I can test my hypothesis.

00:02:52.630 --> 00:02:55.860
So I call the function get on my vocabulary.

00:02:55.860 --> 00:02:58.230
And I pass to it an argument which is the word.

00:02:58.230 --> 00:03:01.880
And my hypothesis is that what it should return, because this line gave

00:03:01.880 --> 00:03:06.140
us the clue, that word number six in document one occurred three times.

00:03:06.140 --> 00:03:06.970
And that's what happens.

00:03:06.970 --> 00:03:10.120
So this way, for any word in the corpus,

00:03:10.120 --> 00:03:14.720
I can figure out what feature number it is in my bag-of-words.

00:03:14.720 --> 00:03:17.270
You can also go the other direction too.

00:03:17.270 --> 00:03:20.150
If you want to ask, for example, what is the word associated with

00:03:20.150 --> 00:03:24.030
feature number six, there's a way you can extract this information too.

00:03:24.030 --> 00:03:27.120
We'll get to that in the next lesson on feature selection in a really

00:03:27.120 --> 00:03:28.650
cool example.

00:03:28.650 --> 00:03:31.180
But now, I want to get your hands on the keyboard with a quiz.

