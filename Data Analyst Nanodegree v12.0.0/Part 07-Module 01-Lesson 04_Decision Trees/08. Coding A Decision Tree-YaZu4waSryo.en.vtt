WEBVTT
Kind: captions
Language: en

00:00:00.490 --> 00:00:02.040
That's right, I am.

00:00:02.040 --> 00:00:03.300
Thanks for that great introduction.

00:00:04.400 --> 00:00:08.420
In this video, I'm going to show you how we can use sklearn to do

00:00:08.420 --> 00:00:13.220
the heavy lifting in terms of creating and training our decision tree.

00:00:13.220 --> 00:00:16.630
We'll start at the documentation page from sklearn for decision trees.

00:00:16.630 --> 00:00:18.350
You can find it using Google.

00:00:18.350 --> 00:00:19.770
When I arrive at the landing page for

00:00:19.770 --> 00:00:23.160
decision trees, I see that I can use them as classifiers.

00:00:23.160 --> 00:00:26.380
They also can be used for regression, which something we'll cover later.

00:00:26.380 --> 00:00:29.150
Scrolling down to find a little bit more information about their use as

00:00:29.150 --> 00:00:33.370
classifiers, I find that there's something called DecisionTreeClassifier,

00:00:33.370 --> 00:00:35.110
which sound like what I want.

00:00:35.110 --> 00:00:39.590
Even better, I find a few lines of starter code that I can use to get going.

00:00:39.590 --> 00:00:42.440
Looking at this starter code a little bit more closely, I see that it's very

00:00:42.440 --> 00:00:46.770
similar to what we had with Naive Bayes and the support vector machines.

00:00:46.770 --> 00:00:49.070
The first thing that I have is an import statement.

00:00:49.070 --> 00:00:52.440
The second important line of code is going to be creating the classifier.

00:00:52.440 --> 00:00:56.010
The third important line is going to be fitting the classifier using in this

00:00:56.010 --> 00:00:57.990
case some training data.

00:00:57.990 --> 00:01:01.880
And then, the fourth important line will be using that fitted classifier to make

00:01:01.880 --> 00:01:05.880
a prediction about a new point, in general a point from the test set.

00:01:05.880 --> 00:01:09.250
So, this should all start to look very familiar to you now.

00:01:09.250 --> 00:01:12.240
So, with that little crash course I'm going to throw you into the deep end of

00:01:12.240 --> 00:01:15.540
the pool now and have you actually code up a decision tree yourself, so

00:01:15.540 --> 00:01:17.060
that you can see what it looks like.

00:01:17.060 --> 00:01:19.610
Then, in the following videos, we'll talk about it a little bit more.

00:01:19.610 --> 00:01:22.390
Here's some starter code that I'll provide for you in a quiz.

00:01:22.390 --> 00:01:25.600
We have our features and our labels for both the training and the testing set.

00:01:25.600 --> 00:01:29.390
What I want you to do is to create a decision tree classifier that you

00:01:29.390 --> 00:01:32.900
train using the training features and the training labels.

00:01:32.900 --> 00:01:35.880
It should be three lines of code to get you to the point where you're fitting

00:01:35.880 --> 00:01:37.260
the decision tree, and

00:01:37.260 --> 00:01:41.520
four lines of code if you decide to make some predictions using the test set.

00:01:41.520 --> 00:01:44.400
I've given you a couple lines of code here that will visualize the decision

00:01:44.400 --> 00:01:47.730
boundary for you so you can see right away what it looks like.

00:01:47.730 --> 00:01:48.350
So, go ahead and

00:01:48.350 --> 00:01:51.470
give that a try and I'll see you in the next video to show you what I got.

