WEBVTT
Kind: captions
Language: en

00:00:00.820 --> 00:00:04.820
&gt;&gt; You did it again, congratulations, your third machine algorithm decision trees,

00:00:04.820 --> 00:00:06.230
you got all the way to the end.

00:00:06.230 --> 00:00:07.810
&gt;&gt; We've learned a lot about decision trees.

00:00:07.810 --> 00:00:11.180
Let's add some of this new found knowledge to our list of things to

00:00:11.180 --> 00:00:13.190
consider when you're picking a classifier.

00:00:13.190 --> 00:00:16.055
&gt;&gt; So they're really easy to use and they're beautiful to grow on.

00:00:16.055 --> 00:00:18.155
They're, they're graphically, in some sense,

00:00:18.155 --> 00:00:20.111
allow you to interpret the data really well, and

00:00:20.111 --> 00:00:23.563
you can really understand them much better then say the result of a support vector machine.

00:00:23.563 --> 00:00:24.821
But they also have limitations.

00:00:24.821 --> 00:00:25.750
&gt;&gt; That's right.

00:00:25.750 --> 00:00:27.585
One of the things that's true about decision trees is

00:00:27.585 --> 00:00:29.090
they're prone to overfitting.

00:00:29.090 --> 00:00:31.880
Especially if you have data that has lots and lots of features and

00:00:31.880 --> 00:00:34.580
a complicated decision tree it can overfit the data.

00:00:34.580 --> 00:00:37.600
So you have to be careful with the parameter tunes that you're picking when you

00:00:37.600 --> 00:00:39.320
use the decision tree to prevent this from happening.

00:00:39.320 --> 00:00:41.300
&gt;&gt; Yeah. What comes out could look crazy if your node has,

00:00:41.300 --> 00:00:42.950
only did single data point.

00:00:42.950 --> 00:00:44.360
You almost always overfit.

00:00:44.360 --> 00:00:47.150
So it is really important for you to measure how well you're doing,

00:00:47.150 --> 00:00:50.300
then stop the growth of the tree at the appropriate time.

00:00:50.300 --> 00:00:52.420
&gt;&gt; One of the things that's also really cool about decision trees,

00:00:52.420 --> 00:00:55.180
though, is that you can build bigger classifiers out of

00:00:55.180 --> 00:00:58.360
decision trees in something called ensemble methods.

00:00:58.360 --> 00:00:59.060
In the next lesson,

00:00:59.060 --> 00:01:02.310
we'll give you a chance to actually explore an algorithm completely on your own.

00:01:02.310 --> 00:01:05.600
And a couple of the ones that will give you as choices are examples of

00:01:05.600 --> 00:01:06.280
ensemble methods.

00:01:06.280 --> 00:01:07.550
So if this sounds interesting to you.

00:01:07.550 --> 00:01:11.413
Building a classifier out of classifier, then stay tuned in the next lesson.

00:01:11.413 --> 00:01:15.820
&gt;&gt; Yeah, you are the super, duper machine liearning researchers on this. So stay tuned.

00:01:15.820 --> 00:01:16.540
&gt;&gt; Let's get started.

