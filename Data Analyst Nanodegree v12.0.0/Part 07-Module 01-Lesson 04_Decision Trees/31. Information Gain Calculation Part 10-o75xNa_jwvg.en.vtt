WEBVTT
Kind: captions
Language: en

00:00:00.420 --> 00:00:03.910
As it happens when we split based on speed limit we get

00:00:03.910 --> 00:00:07.540
perfect purity of the branches that we make as a result.

00:00:07.540 --> 00:00:10.510
So our information gain is going to be equal to 1.

00:00:10.510 --> 00:00:13.290
We started out with an entropy of 1.

00:00:13.290 --> 00:00:14.970
At the end we had an entropy of 0.

00:00:14.970 --> 00:00:16.800
So the information gain is going to be 1.

00:00:16.800 --> 00:00:19.380
So this is the best information gain that we can have,

00:00:19.380 --> 00:00:21.070
definitely this is where we want to make a split.

00:00:22.120 --> 00:00:25.500
And just to sketch out the decision tree it would look something like this.

00:00:25.500 --> 00:00:28.910
Where when we look at samples where the speed limit is in effect,

00:00:28.910 --> 00:00:31.660
so these first two rows where the answer for

00:00:31.660 --> 00:00:35.940
speed limit is yes, then we get all of our slow examples over there.

00:00:35.940 --> 00:00:41.130
On the other side when there's no speed limit, everything is going to be fast.

00:00:41.130 --> 00:00:44.540
So this has just been a very simple calculation.

00:00:44.540 --> 00:00:46.570
It still took us a while to get through, but

00:00:46.570 --> 00:00:48.440
I hope you have a little bit of a better sense for

00:00:48.440 --> 00:00:52.480
what information gain is in decision trees and why it's so important.

00:00:52.480 --> 00:00:56.540
So, it's calculations like this that the decision tree is figuring out when it

00:00:56.540 --> 00:00:57.200
does the training.

00:00:57.200 --> 00:01:00.400
It looks at all the training examples, all of the different features that

00:01:00.400 --> 00:01:03.710
are available to it, and it uses this information gain

00:01:03.710 --> 00:01:08.370
criterion in deciding which variables to split on, and how to make the splits.

