WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.819
我们来看一些常见数据问题的解决方式

00:00:03.819 --> 00:00:07.344
这是我为本课程创建的一个小型数据集

00:00:07.344 --> 00:00:09.240
其中有 11 项用户产品互动记录

00:00:09.240 --> 00:00:15.378
记录了用户是否喜爱产品 (liked 字段)

00:00:15.378 --> 00:00:17.565
浏览产品的时长 (view_duration 字段)

00:00:17.565 --> 00:00:21.214
是通过网站浏览还是移动应用浏览 (source 字段)

00:00:21.214 --> 00:00:24.890
又是在何时开始浏览的 (timestamp 字段)

00:00:24.890 --> 00:00:30.524
暂停本视频 试试看你能否找出这批数据的潜在问题

00:00:30.524 --> 00:00:37.125
我们来处理这个数据集里的三个问题 这些问题在现实中很常见

00:00:37.125 --> 00:00:42.465
第一个是缺失数据 问题出现在 view_duration 一列中

00:00:42.465 --> 00:00:46.734
这个数据集总共录入了 11 条数据 也就是 11 行

00:00:46.734 --> 00:00:50.759
可 view_duration 一列仅有 8 个非空值 (non-null)

00:00:50.759 --> 00:00:55.125
这也就意味着有三个空值 大家从这里也可以看出来

00:00:55.125 --> 00:00:57.323
这只是个小型数据集

00:00:57.323 --> 00:00:59.640
所以我们能在这看到所有空值

00:00:59.640 --> 00:01:04.795
但是通常在更大的数据集中 你得在这里进行空值检查

00:01:04.795 --> 00:01:10.200
我们要处理的第二个问题是冗余 可参见第三和第四行

00:01:10.200 --> 00:01:15.555
还是那个道理 现在我们之所以能发现这个问题 只是因为这是一个小型数据集

00:01:15.555 --> 00:01:19.595
等下我会教你一个更好的办法来查找冗余数据

00:01:19.594 --> 00:01:22.804
第三个要解决的问题是数据类型错误

00:01:22.805 --> 00:01:27.810
这里的 timestamp (时间戳) 为字符串

00:01:27.810 --> 00:01:30.579
可理想情况下 timestamp 应为 datetime 对象

00:01:30.579 --> 00:01:33.299
记住 这里显示为 object 而不是 string

00:01:33.299 --> 00:01:37.534
是因为 pandas 存储的是字符串的指针 而不是字符串本身

00:01:37.534 --> 00:01:42.215
现在我们从第一个问题开始解决 也就是数据缺失

00:01:42.215 --> 00:01:45.880
数据缺失要如何处理 取决于不同的因素

00:01:45.879 --> 00:01:48.789
如值缺失的原因

00:01:48.790 --> 00:01:52.775
缺失是否为随机情况等

00:01:52.775 --> 00:01:56.140
处理办法之一是用平均值填充缺失值

00:01:56.140 --> 00:02:00.640
pandas 里有个很方便的函数 能让你快捷高效地完成这一操作

00:02:00.640 --> 00:02:05.114
首先 我们要取得 view_duration 一列的平均值

00:02:05.114 --> 00:02:10.079
然后 用 pandas 的 fillna 函数把平均值填充到各空值处

00:02:10.080 --> 00:02:12.697
看看现在的 DataFrame

00:02:12.697 --> 00:02:14.375
问题解决了吗？

00:02:14.375 --> 00:02:17.657
函数并没有修改原来的列

00:02:17.657 --> 00:02:22.215
只是把更改返回成一个新列 这一列并没有储存到任何地方

00:02:22.215 --> 00:02:23.676
为了保存更改

00:02:23.675 --> 00:02:27.789
要记住像这样把更改赋值到原来的列里

00:02:27.789 --> 00:02:30.118
你也可以用一个叫 inplace 的参数

00:02:30.118 --> 00:02:34.990
来实现“原地”更改

00:02:34.990 --> 00:02:37.990
好极了 数据缺失问题解决了

00:02:37.990 --> 00:02:41.625
接下来要处理的是数据冗余问题

00:02:41.625 --> 00:02:44.824
导致数据冗余的原因有很多

00:02:44.824 --> 00:02:48.459
比如数据源合并或人为过失

00:02:48.460 --> 00:02:51.020
这个情景里问题很简单 只有两行

00:02:51.020 --> 00:02:53.564
也就是第三和第四行相同

00:02:53.564 --> 00:02:57.294
这个小型数据集很小 看一眼都能数出来

00:02:57.294 --> 00:02:58.652
但对于大型数据集

00:02:58.652 --> 00:03:02.620
你可以用 duplicated 函数来查看冗余行有哪些

00:03:02.620 --> 00:03:07.194
该函数默认将非首次出现的冗余行标为 True

00:03:07.194 --> 00:03:12.129
除非行中每列的值都相同 不然该行不会被视为冗余

00:03:12.129 --> 00:03:15.924
你可以用不同的参数更改这两个默认设置

00:03:15.925 --> 00:03:17.760
对于大些的数据集

00:03:17.759 --> 00:03:19.739
有个办法可能更有帮助

00:03:19.740 --> 00:03:22.450
那就是像这样计算数据集数据冗余的数量

00:03:22.449 --> 00:03:27.179
要删除冗余值 我们可以用 pandas 的 drop_duplicates 函数

00:03:27.180 --> 00:03:29.969
和之前一样 使用该函数时 我们也要用 inplace 参数

00:03:29.969 --> 00:03:33.444
或手动把输出结果赋值到原始 DataFrame 中

00:03:33.444 --> 00:03:35.219
正如你看到的 我们删掉了第四行

00:03:35.219 --> 00:03:37.520
也就是标为冗余的那行

00:03:37.520 --> 00:03:41.844
不过这个情景很简单 整行数据都一样

00:03:41.844 --> 00:03:46.090
你可以想象那些较为复杂的数据冗余情景

00:03:46.090 --> 00:03:50.430
比如 假设我们手里有一家医院的患者数据

00:03:50.430 --> 00:03:53.939
如果你看到两行数据有相同的患者 ID

00:03:53.939 --> 00:03:59.099
却记录着不同的体检结果 那怎么办？ 是要把两行数据合并起来呢？

00:03:59.099 --> 00:04:01.489
还是保留最新的那一行？

00:04:01.489 --> 00:04:05.034
这时候你就得调查更多信息了

00:04:05.034 --> 00:04:07.719
在这个情景中 你可能要只根据患者 ID 列

00:04:07.719 --> 00:04:11.544
来判断冗余与否

00:04:11.544 --> 00:04:18.298
你可以在 duplicated 和 drop_duplicate 函数中使用 subset 参数

00:04:18.298 --> 00:04:22.259
最后 我们来解决第三个问题 数据类型错误

00:04:22.259 --> 00:04:27.224
错误的数据类型也是数据分析师频频遇到的问题

00:04:27.225 --> 00:04:32.210
在这里 时间戳以字符串类型呈现 而不是 datetime 类型

00:04:32.209 --> 00:04:36.805
这虽然不是什么大问题 但如果你想更轻松地从中提取具体信息

00:04:36.805 --> 00:04:41.040
或对其进行过滤的话 datetime 型处理起来会更方便

00:04:41.040 --> 00:04:48.015
我们来使用 pandas 的 to_datetime 函数 将本列转换为 datetime 型

00:04:48.014 --> 00:04:52.129
现在我们可以看到 timestamp 已经是 datetime 型了

00:04:52.129 --> 00:04:56.675
顺便说一句 完成修改后 就算你把更改保存到 CSV 文件里

00:04:56.675 --> 00:05:00.975
下次打开 文件仍会默认将数据读为字符串类型

00:05:00.975 --> 00:05:02.990
所以下次打开 CSV 文件 你还是得再转一次类型

00:05:02.990 --> 00:05:08.439
或者在 read_csv 函数中使用诸如 parsedates 之类的参数

00:05:08.439 --> 00:05:13.050
不过 如果你要解析的字符串是非常规的格式

00:05:13.050 --> 00:05:18.000
那么用 to_datetime 函数比用 read_csv 函数的参数选择面更大些

