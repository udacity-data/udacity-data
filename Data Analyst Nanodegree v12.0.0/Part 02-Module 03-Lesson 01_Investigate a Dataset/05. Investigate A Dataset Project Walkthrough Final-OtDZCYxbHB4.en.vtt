WEBVTT
Kind: captions
Language: en

00:00:08.150 --> 00:00:13.110
Hi everyone. Welcome to the project work through for investigate a dataset.

00:00:13.110 --> 00:00:15.000
I'll be doing the project with you today,

00:00:15.000 --> 00:00:16.660
and you can see my process.

00:00:16.660 --> 00:00:19.220
This project seems to be more open-ended,

00:00:19.220 --> 00:00:21.980
where you choose a dataset, and you analyze it.

00:00:21.980 --> 00:00:25.935
It looks like you'll need to install pandas, NumPy, and matplotlib.

00:00:25.935 --> 00:00:28.060
You probably don't need to install CSV, though,

00:00:28.060 --> 00:00:30.740
if you could use read CSV from pandas.

00:00:30.740 --> 00:00:35.285
Hopefully, you install these using Anaconda in the previous lessons.

00:00:35.285 --> 00:00:38.315
So, the first step is to choose your dataset,

00:00:38.315 --> 00:00:43.360
and you can use this link to read about the different dataset options you have,

00:00:43.360 --> 00:00:46.660
and some questions you can ask for your analysis.

00:00:46.660 --> 00:00:49.670
Today I'll be working through the Titanic dataset which

00:00:49.670 --> 00:00:52.270
is not an option for this project here.

00:00:52.270 --> 00:00:56.615
But I'll be going through the same process and following the same guidelines.

00:00:56.615 --> 00:01:02.640
The final deliverable for this project is a report and Python code for your analysis.

00:01:02.640 --> 00:01:04.450
If you're using a Jupyter notebook,

00:01:04.450 --> 00:01:08.895
you can include these two in the same file as long as you use like mark

00:01:08.895 --> 00:01:11.750
down cells and comments and stuff like that

00:01:11.750 --> 00:01:15.095
to clearly communicate your findings and process.

00:01:15.095 --> 00:01:17.130
Also you can ignore these tabs here,

00:01:17.130 --> 00:01:20.380
this are tabs that you probably won't see from your end.

00:01:20.380 --> 00:01:26.855
This is the template that you'll use or can use for this project.

00:01:26.855 --> 00:01:29.730
It's also available to download just by pressing

00:01:29.730 --> 00:01:33.635
file download as I've had in the iPython notebook if you prefer to do it locally.

00:01:33.635 --> 00:01:37.095
You could also get it over here.

00:01:37.095 --> 00:01:39.385
So, in your final project,

00:01:39.385 --> 00:01:43.070
you should have a note specifying what data set you analyzed,

00:01:43.070 --> 00:01:45.525
a statement of the questions you posed,

00:01:45.525 --> 00:01:49.585
a description of what you did to investigate those questions,

00:01:49.585 --> 00:01:52.405
documentation of any data wrangling you did,

00:01:52.405 --> 00:01:55.810
and summary statistics and plots to communicate your final result.

00:01:55.810 --> 00:01:58.165
This should be in a PDF or html file,

00:01:58.165 --> 00:02:00.950
but if you do use iPython notebook you can

00:02:00.950 --> 00:02:06.680
just download it as a a html file from Jupyter notebooks.

00:02:06.680 --> 00:02:08.620
I already downloaded the dataset,

00:02:08.620 --> 00:02:11.465
so I'll just go to this notebook,

00:02:11.465 --> 00:02:16.045
and I'm going to upload the dataset that I had.

00:02:16.045 --> 00:02:19.055
Also you can just do this locally if you prefer that.

00:02:19.055 --> 00:02:23.200
Either way you will just be downloading it as html file like this,

00:02:23.200 --> 00:02:27.070
whether it's here or locally and then submitting this file.

00:02:27.070 --> 00:02:29.255
So, let's take a look at this notebook.

00:02:29.255 --> 00:02:31.850
Throughout the notebook, there are little tips here that will tell

00:02:31.850 --> 00:02:35.415
you some advice on how to organize your report,

00:02:35.415 --> 00:02:38.655
as well some advice on your analysis.

00:02:38.655 --> 00:02:45.720
Here I'm going to replace the name with something more specific to mine, so my projects.

00:02:45.720 --> 00:02:47.945
So, Titanic data analysis,

00:02:47.945 --> 00:02:51.030
and I'll keep the table of contents because that is cool.

00:02:51.030 --> 00:02:54.925
Here you just provide a brief introduction to dataset,

00:02:54.925 --> 00:02:56.260
and your project I guess.

00:02:56.260 --> 00:02:58.420
So, I would say something like,

00:02:58.420 --> 00:03:01.210
in this project we'll be analyzing data associated with

00:03:01.210 --> 00:03:04.545
the tragic event of the sinking Titanic.

00:03:04.545 --> 00:03:09.460
In particular, we'll be interested in finding trends among the passengers who survived,

00:03:09.460 --> 00:03:12.575
and how they differed from the passengers who did not survive.

00:03:12.575 --> 00:03:17.190
To start, we'll import the packages we need for this analysis.

00:03:17.190 --> 00:03:24.175
So, NumPy, pandas matplotlib,

00:03:24.175 --> 00:03:28.520
and seaborne because not necessary but makes

00:03:28.520 --> 00:03:34.380
visualizations look nice and matplotlib in line,

00:03:34.870 --> 00:03:38.920
to make sure that those visualizations pop up in Jupyter notebooks.

00:03:38.920 --> 00:03:40.915
The next section is data wrangling.

00:03:40.915 --> 00:03:45.285
This is just where you inspect your data to understand its structure,

00:03:45.285 --> 00:03:48.470
and figure out any changes we have to make.

00:03:48.470 --> 00:03:50.995
Here's where you actually make the changes to clean them.

00:03:50.995 --> 00:03:54.300
So, let's first look at our dataset.

00:03:54.850 --> 00:03:58.610
I need to read in the dataset.

00:03:58.610 --> 00:04:01.535
So, there's the passenger ID.

00:04:01.535 --> 00:04:02.935
Each row is a passenger.

00:04:02.935 --> 00:04:05.670
This is just a unique identifier,

00:04:05.670 --> 00:04:07.965
whether they survived or not in ones and zeros.

00:04:07.965 --> 00:04:11.170
The clustering their name, gender, age,

00:04:11.170 --> 00:04:13.570
the number of siblings and spouses they have,

00:04:13.570 --> 00:04:15.850
number of parents and children they have, the ticket,

00:04:15.850 --> 00:04:18.860
fare, cabin and in embarks.

00:04:18.860 --> 00:04:20.260
This is just what they paid,

00:04:20.260 --> 00:04:21.915
and where they embarked from,

00:04:21.915 --> 00:04:26.845
there's three C, S and Q according to Kaggle dogs,

00:04:26.845 --> 00:04:30.920
and in your report you should probably include description of their columns,

00:04:30.920 --> 00:04:33.460
and remember just over here it says,

00:04:33.460 --> 00:04:38.825
use a lot of cells like you can press B to keep creating new cells or X to delete them,

00:04:38.825 --> 00:04:40.670
and if you want to turn them to mark-down just press

00:04:40.670 --> 00:04:43.455
M. If you're wondering why you can't use these,

00:04:43.455 --> 00:04:46.480
like while you're editing, it's because you're editing.

00:04:46.480 --> 00:04:51.155
So, you need to escape and then use those shortcuts.

00:04:51.155 --> 00:04:54.010
The next thing I'm going to do is,

00:04:54.010 --> 00:04:56.110
look at the shape.

00:04:56.110 --> 00:05:00.835
So, there are 891 passengers and 12 columns.

00:05:00.835 --> 00:05:04.300
Here are some summary statistics.

00:05:04.300 --> 00:05:07.990
Again, we're just trying to understand our data a little bit more,

00:05:07.990 --> 00:05:10.930
and also identify any changes will have to make.

00:05:10.930 --> 00:05:13.155
Although, this data does look really clean.

00:05:13.155 --> 00:05:16.060
We probably won't be analyzing the passenger ID or

00:05:16.060 --> 00:05:19.415
the name for our analysis because those are very specific to the passenger.

00:05:19.415 --> 00:05:22.300
Ticket and cabin I don't suspect to be super

00:05:22.300 --> 00:05:25.905
useful in finding trends between survival as well.

00:05:25.905 --> 00:05:29.175
Again, these are all things you can change.

00:05:29.175 --> 00:05:31.110
It's all up to you. You should just make sure,

00:05:31.110 --> 00:05:34.925
and the decisions you make are explained and elaborated on,

00:05:34.925 --> 00:05:37.100
in mark-down cells or comments.

00:05:37.100 --> 00:05:39.240
Just to let the reader know what you're doing.

00:05:39.240 --> 00:05:42.225
So, just from these summary statistics,

00:05:42.225 --> 00:05:47.000
I can see that there are 38 percent of the passengers survived,

00:05:47.000 --> 00:05:49.150
there are three classes; one, two, and three,

00:05:49.150 --> 00:05:53.020
and over 50 percent or at least 50 percent of them are in third class,

00:05:53.020 --> 00:05:56.165
which I assume is the cheapest and lowest class.

00:05:56.165 --> 00:06:00.890
There are very young babies and also an 18-year-old in this ship.

00:06:00.890 --> 00:06:05.595
But the majority of them are between 20 and 40 years old.

00:06:05.595 --> 00:06:08.610
Most of them came without siblings or spouses,

00:06:08.610 --> 00:06:10.415
and without parents and children.

00:06:10.415 --> 00:06:13.745
Although, some can have as much as eight or six.

00:06:13.745 --> 00:06:16.790
The fares are generally between 730,

00:06:16.790 --> 00:06:20.145
830, although, someone did pay 512.

00:06:20.145 --> 00:06:22.455
I am assuming that is first-class,

00:06:22.455 --> 00:06:24.505
and this is third- class.

00:06:24.505 --> 00:06:27.920
We can check that later. But I'm assuming this is correlated with that.

00:06:27.920 --> 00:06:32.840
Also, you can probably see here that the age has some missing values.

00:06:32.840 --> 00:06:35.455
So, the age has some missing values,

00:06:35.455 --> 00:06:38.560
as well as the cabin and embarked.

00:06:38.560 --> 00:06:40.750
Although, we probably won't be analyzing cabin.

00:06:40.750 --> 00:06:45.435
So, the first thing I'm going to do before I drop stuff,

00:06:45.435 --> 00:06:48.120
drop specific rows with no values or fill in

00:06:48.120 --> 00:06:52.760
no values is drop the columns I'm not going to use.

00:06:52.760 --> 00:06:58.680
So, I'm going to go ahead and drop the passenger ID,

00:06:58.680 --> 00:07:02.230
name, ticket, and cabin.

00:07:02.230 --> 00:07:04.690
Also if you're cleaning this data,

00:07:04.690 --> 00:07:07.965
you could also change everything to lowercase if you want.

00:07:07.965 --> 00:07:10.090
Sometimes I do that just to be consistent because I

00:07:10.090 --> 00:07:13.210
don't like remembering what's lowercase and uppercase.

00:07:13.210 --> 00:07:18.715
Axis equals one to tell the function that we're using the column names or the columns,

00:07:18.715 --> 00:07:23.230
and in places true so that we keep those changes.

00:07:23.230 --> 00:07:26.195
Now, we have the survived, class, gender,

00:07:26.195 --> 00:07:30.165
age, family, staff, fare, and embarked.

00:07:30.165 --> 00:07:34.520
Now,what we have to do is fill in the age and the embarked.

00:07:34.520 --> 00:07:37.370
I'll just handle them. For the age,

00:07:37.370 --> 00:07:39.020
there seems to be a lot that are missing.

00:07:39.020 --> 00:07:43.910
So, sometimes what I like to do is just look at what the rows look like.

00:07:43.910 --> 00:07:46.580
Because if they all have some certain characteristic,

00:07:46.580 --> 00:07:48.145
it will be like, good to know.

00:07:48.145 --> 00:07:50.830
Because there were sometimes I was like looking at projects

00:07:50.830 --> 00:07:54.655
where all the null values are all from the same group or something.

00:07:54.655 --> 00:07:58.955
So, I just want to make sure I'm not missing anything.

00:07:58.955 --> 00:08:07.720
So I'll look at the data frame where the age is null and I look at a histogram of that.

00:08:08.310 --> 00:08:11.905
I didn't even look at the histogram of the whole data frame.

00:08:11.905 --> 00:08:14.085
Okay. I'll do that first.

00:08:14.085 --> 00:08:17.605
So, this is the entire data frame.

00:08:17.605 --> 00:08:21.105
This agrees with what we saw in the summary statistics.

00:08:21.105 --> 00:08:23.655
The majority of them didn't pay too much,

00:08:23.655 --> 00:08:26.630
is very skewed to the right.

00:08:26.630 --> 00:08:29.270
Most people are in the third-class.

00:08:29.270 --> 00:08:33.115
More people didn't survive then survived.

00:08:33.115 --> 00:08:35.820
Also most people didn't come with parents,

00:08:35.820 --> 00:08:38.280
children, siblings, or spouses.

00:08:38.409 --> 00:08:43.824
Ages also skewed to the right with the majority being around 20 and 40.

00:08:43.825 --> 00:08:50.170
I just did this because I wanted to check that these weren't super off from the general,

00:08:50.170 --> 00:08:52.115
the rest of the data.

00:08:52.115 --> 00:08:55.190
The fare is also skewed to the right.

00:08:55.190 --> 00:08:56.950
Mostly, in the third-class.

00:08:56.950 --> 00:09:01.200
Although, most of the null I think is mostly,

00:09:01.200 --> 00:09:04.925
more people from these rows are in the third-class.

00:09:04.925 --> 00:09:07.400
Then survive more than survive,

00:09:07.400 --> 00:09:09.070
not that much family,

00:09:09.070 --> 00:09:11.100
and the ages we obviously know.

00:09:11.100 --> 00:09:17.610
So, I'm just going to fill in the null values with the mean.

00:09:17.610 --> 00:09:19.060
There are better ways to do this,

00:09:19.060 --> 00:09:20.540
but this is pretty simple.

00:09:20.540 --> 00:09:22.905
So, I will do that.

00:09:22.905 --> 00:09:25.125
I forgot to do in-place.

00:09:25.125 --> 00:09:26.845
Do not forget that.

00:09:26.845 --> 00:09:30.410
So, the ages were all filled with the means.

00:09:30.410 --> 00:09:32.330
But the other one that we need to fill which was

00:09:32.330 --> 00:09:34.690
embarked the knot because this is not numeric data,

00:09:34.690 --> 00:09:36.585
doesn't have a mean is just letters.

00:09:36.585 --> 00:09:39.815
But it looks like there's only two missing,

00:09:39.815 --> 00:09:44.515
and those appear to be, these two rows.

00:09:44.515 --> 00:09:48.875
So, I think it'll be okay if we just drop them. So, yeah.

00:09:48.875 --> 00:09:53.760
Now we have a total of 889 rows instead of 891.

00:09:53.760 --> 00:09:56.780
So, I think that's all I needed to do for

00:09:56.780 --> 00:09:59.990
the cleaning because otherwise this dataset is pretty clean.

00:09:59.990 --> 00:10:03.485
So the next step is, Exploratory Data Analysis.

00:10:03.485 --> 00:10:07.600
Also I'm just using this template right now to see what we have to do,

00:10:07.600 --> 00:10:10.860
because either way these little header should be

00:10:10.860 --> 00:10:15.440
more specific section names for your analysis.

00:10:15.440 --> 00:10:18.300
But, there are useful tips and notes here.

00:10:18.300 --> 00:10:21.630
Just make sure analysis directed by questions.

00:10:21.630 --> 00:10:26.590
So, survived is my dependent variable and these are my independent variables.

00:10:26.590 --> 00:10:30.070
I'll just be exploring those associations among them.

00:10:30.070 --> 00:10:35.380
So, I guess the first question I'll ask is whether the fare is associated with survival?

00:10:35.380 --> 00:10:38.910
Because I expect the expensive,

00:10:38.910 --> 00:10:42.950
people with high classes and expensive fares I

00:10:42.950 --> 00:10:47.110
think may have a higher chance of surviving.

00:10:47.110 --> 00:10:51.050
So, to make it easier to grab these rows easily in the future as well,

00:10:51.050 --> 00:10:53.050
I'm going to create masks for

00:10:53.050 --> 00:10:57.160
rows where the passenger survived and rows where they did not.

00:10:57.160 --> 00:11:01.020
So, if I want to see all the fare is I could do something like,

00:11:01.020 --> 00:11:03.380
fares of all the people who survived.

00:11:03.380 --> 00:11:06.060
I could just do something like this which makes it a lot easier.

00:11:06.060 --> 00:11:08.020
So, let's look at the mean of that,

00:11:08.020 --> 00:11:12.505
as well as for the people who did not survive.

00:11:12.505 --> 00:11:17.930
It does look like the people who survived had a much higher well,

00:11:17.930 --> 00:11:21.770
a significant amount higher than the people who did not.

00:11:21.770 --> 00:11:25.200
But we can see this more clearly if we look at the distribution

00:11:25.200 --> 00:11:28.710
of fares and compare them in a visual.

00:11:28.710 --> 00:11:31.450
So, let's do that.

00:11:31.450 --> 00:11:35.070
You actually need a semicolon the last one to make sure the output doesn't pop up.

00:11:35.070 --> 00:11:37.960
I'm also going to include a label in each one to make it

00:11:37.960 --> 00:11:44.060
clear what each one is and make it a bit more transparent,

00:11:44.060 --> 00:11:48.850
so we can see more clearly where they overlap.

00:11:48.850 --> 00:11:52.535
So, yeah definitely does look like the people who survived

00:11:52.535 --> 00:11:56.045
had generally higher fares than the people who did not.

00:11:56.045 --> 00:12:00.734
Especially with the lower class much more people died than survived.

00:12:00.734 --> 00:12:03.860
You'd set the bin number of bins or

00:12:03.860 --> 00:12:07.520
columns to make it more generalized or not generalized.

00:12:07.520 --> 00:12:10.785
So, if we use like 20 for example,

00:12:10.785 --> 00:12:16.605
we could see even more specific information of bins.

00:12:16.605 --> 00:12:21.050
But fare also seems like it would be very closely correlated with class.

00:12:21.050 --> 00:12:23.905
So, let's take a look at that as well.

00:12:23.905 --> 00:12:30.775
So, if we grouped by the class and then we look at the Survived column,

00:12:30.775 --> 00:12:33.525
it does definitely look like the higher the class,

00:12:33.525 --> 00:12:35.945
the more likely you are to survive.

00:12:35.945 --> 00:12:38.290
If you want to use a visual foreign analysis,

00:12:38.290 --> 00:12:40.340
we could just plot this in

00:12:40.340 --> 00:12:45.445
a bar chart and again use semicolon if you don't want that output.

00:12:45.445 --> 00:12:48.375
Yeah, there definitely seems to be a correlation here.

00:12:48.375 --> 00:12:51.765
Similarly, I want to compare the distribution of

00:12:51.765 --> 00:12:55.625
ages for the passengers who survived and didn't survive.

00:12:55.625 --> 00:12:59.360
So, I'll just copy and paste this and replace

00:12:59.360 --> 00:13:03.875
this with age because it's a very similar, very similar.

00:13:03.875 --> 00:13:05.250
So, based on this plot,

00:13:05.250 --> 00:13:08.115
it does look like the really young children

00:13:08.115 --> 00:13:11.850
have a higher chance of surviving than other ages,

00:13:11.850 --> 00:13:15.345
but other than that it doesn't look like they're too correlated.

00:13:15.345 --> 00:13:18.670
Next we can also look at the gender.

00:13:18.670 --> 00:13:21.850
Also remember to be very descriptive and

00:13:21.850 --> 00:13:25.730
detailed in markdown cells to describe your analysis,

00:13:25.730 --> 00:13:27.555
if you're doing this in Jupyter notebook.

00:13:27.555 --> 00:13:29.775
So, if we want to look at the gender,

00:13:29.775 --> 00:13:33.025
we can also group by again,

00:13:33.025 --> 00:13:35.580
group by sex and then look at

00:13:35.580 --> 00:13:41.625
the survived column and you can also plot this in a bar chart.

00:13:41.625 --> 00:13:44.110
It does look like females are

00:13:44.110 --> 00:13:49.080
definitely there are definitely more female surviving than men but just to make

00:13:49.080 --> 00:13:52.140
sure I want to see if this isn't for

00:13:52.140 --> 00:13:53.800
some other weird reason like there are

00:13:53.800 --> 00:13:56.850
very few females and they just happened to meet first-class or something.

00:13:56.850 --> 00:13:59.575
So, first I want to just check,

00:13:59.575 --> 00:14:02.730
there are definitely more males than females.

00:14:02.730 --> 00:14:06.770
If we do, lets say this.

00:14:06.770 --> 00:14:12.075
If we group by gender and we look at their classes,

00:14:12.075 --> 00:14:15.005
maybe a clear way to see this is the fare.

00:14:15.005 --> 00:14:17.095
So, we can do something like,

00:14:17.095 --> 00:14:22.550
we can look at the median fares for each gender and it

00:14:22.550 --> 00:14:27.325
does look like the women are in more expensive,

00:14:27.325 --> 00:14:35.045
are spending more, probably more in first class but let's see this visually.

00:14:35.045 --> 00:14:40.040
So, ideally you'd be using Matplotlib and making like a nice looking double histogram,

00:14:40.040 --> 00:14:42.840
but I'm trying to show you really quickly my analysis.

00:14:42.840 --> 00:14:45.940
But even if you separate them by class,

00:14:45.940 --> 00:14:48.765
it is very clear that the women are surviving more than men.

00:14:48.765 --> 00:14:55.675
So, there does seem to be a pretty strong association between gender and survival.

00:14:55.675 --> 00:15:01.580
Another thing we can analyse is how having family on board is associated with survival,

00:15:01.580 --> 00:15:05.370
and we can analyse this using the columns for siblings and spouses,

00:15:05.370 --> 00:15:08.135
as well as the parents and children.

00:15:08.135 --> 00:15:13.440
I'm imagining another double bar chart but I'm going to try doing

00:15:13.440 --> 00:15:18.825
something a little bit better than this but still using pandas.

00:15:18.825 --> 00:15:25.065
So, I'm going to use the analyser siblings and spouses column first

00:15:25.065 --> 00:15:27.600
and use this mask again to see those that

00:15:27.600 --> 00:15:33.300
survived and get the value counts because we're plotting a bar chart.

00:15:33.300 --> 00:15:39.470
I'm going to do the same thing with those who did not survive and

00:15:39.470 --> 00:15:45.820
these are just basically going to be on top of each other with different colours.

00:15:45.820 --> 00:15:50.950
Ideally, also you'd be using Matplotlib but I'm just doing

00:15:50.950 --> 00:15:56.440
this really quickly to show you guys my analysis first.

00:15:56.440 --> 00:16:02.830
So, you can see that we need to be clear it labels.

00:16:02.830 --> 00:16:07.030
So, I'm going to insert a label here so we know which colour's which.

00:16:07.030 --> 00:16:13.670
I'm going to semicolon to get rid of this output.

00:16:13.670 --> 00:16:19.760
So, a lot of people who have lots of families don't appear to be surviving.

00:16:20.140 --> 00:16:24.390
People who have one survived more by

00:16:24.390 --> 00:16:28.160
a little bit and then majority of people were alone did not survive,

00:16:28.160 --> 00:16:35.140
probably also imagine most of the population is probably in this category,

00:16:35.140 --> 00:16:38.070
so and most people did not survive.

00:16:38.070 --> 00:16:44.900
We can do the same thing with the parents and children column and we see

00:16:44.900 --> 00:16:47.810
a similar trend here where the people with big families don't appear to

00:16:47.810 --> 00:16:52.015
survive as well as those who are alone.

00:16:52.015 --> 00:16:55.505
Maybe these are correlated with the first class or second class.

00:16:55.505 --> 00:16:57.740
These are all things that can be explored

00:16:57.740 --> 00:17:01.535
more and lastly the other column we can explore is,

00:17:01.535 --> 00:17:06.520
how were they impact from where two is associated with survival.

00:17:06.880 --> 00:17:11.365
We can do a similar thing with this too.

00:17:11.365 --> 00:17:14.920
Also when you submit your report this should all be labeled.

00:17:14.920 --> 00:17:17.970
So, to have a title, the axis labels,

00:17:17.970 --> 00:17:22.740
legend is good and like appropriate better tick labels

00:17:22.740 --> 00:17:27.405
in this and just using Matplotlib for.

00:17:27.405 --> 00:17:33.375
So, the people in the S category seemed to be not having as much luck,

00:17:33.375 --> 00:17:34.830
C a bit better,

00:17:34.830 --> 00:17:35.960
Q is also not that great.

00:17:35.960 --> 00:17:38.960
So, embark does that seem to have some association with it.

00:17:38.960 --> 00:17:42.020
So, this was just a really quick run-through of

00:17:42.020 --> 00:17:45.770
like the exploring associations among the variables,

00:17:45.770 --> 00:17:48.480
independent and dependent variables are going to rubic.

00:17:48.480 --> 00:17:50.100
It looks like you only need to have

00:17:50.100 --> 00:17:55.130
at least three independent variables and one dependent in your analysis.

00:17:55.130 --> 00:17:57.555
At the bottom over here,

00:17:57.555 --> 00:18:03.365
you should quickly summarise your findings and discuss limitations in your analysis,

00:18:03.365 --> 00:18:08.590
like for example, when I filled in the null values for the ages,

00:18:08.590 --> 00:18:12.030
I just used the mean and there could be a better way of doing that.

00:18:12.030 --> 00:18:13.110
You could take into account

00:18:13.110 --> 00:18:18.980
the other values in those rows where the ages now and use regression or something

00:18:18.980 --> 00:18:20.880
to make a more accurate prediction of

00:18:20.880 --> 00:18:26.385
what that could be and just places where you could explore more things.

00:18:26.385 --> 00:18:28.315
But yeah, just make sure you use,

00:18:28.315 --> 00:18:30.255
you organise your report well,

00:18:30.255 --> 00:18:32.180
use headings, use markdown cells.

00:18:32.180 --> 00:18:36.100
If you have a report, same thing and clean up

00:18:36.100 --> 00:18:40.060
your visuals and just be very thorough with your descriptions.

00:18:40.060 --> 00:18:44.690
So, in this video I narrated it a lot but in a report,

00:18:44.690 --> 00:18:49.725
you should describe everything and write it down.

00:18:49.725 --> 00:18:55.020
I hope this was helpful and good luck with your analysis.
最新课程跟课件还有一对一辅导请加wx：udacity6
