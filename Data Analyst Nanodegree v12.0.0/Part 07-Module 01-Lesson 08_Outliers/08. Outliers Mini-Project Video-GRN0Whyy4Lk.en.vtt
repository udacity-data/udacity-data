WEBVTT
Kind: captions
Language: en

00:00:00.330 --> 00:00:02.780
Welcome to the mini project on outliers.

00:00:02.780 --> 00:00:04.310
As you saw in the last lesson,

00:00:04.310 --> 00:00:08.350
having large outliers can have a big effect on your regression result.

00:00:08.350 --> 00:00:10.080
So in the first part of this mini project,

00:00:10.080 --> 00:00:13.340
you're going to implement the algorithm that Sebastian has suggested to us.

00:00:13.340 --> 00:00:15.560
So what that means is you take the 10% or

00:00:15.560 --> 00:00:19.940
so of data points that have the largest residuals, relative to your regression.

00:00:19.940 --> 00:00:22.510
You remove them, and then you refit the regression, and

00:00:22.510 --> 00:00:24.150
you see how the result changes.

00:00:24.150 --> 00:00:27.120
You'll be implementing that algorithm in this mini project.

00:00:27.120 --> 00:00:30.410
The second thing we'll do is take a closer at the Enron data.

00:00:30.410 --> 00:00:33.050
This time with a particular eye towards outliers.

00:00:33.050 --> 00:00:35.820
You'll find very quickly that there are some data points that fall

00:00:35.820 --> 00:00:37.930
far outside of the general pattern.

00:00:37.930 --> 00:00:40.630
So we'll talk about these explicitly, and whether this means they should be

00:00:40.630 --> 00:00:45.190
removed or they should be given extra special or extra heavy consideration.

00:00:45.190 --> 00:00:47.200
It's really cool and I think you will really enjoy it.

