WEBVTT
Kind: captions
Language: en

00:00:00.230 --> 00:00:03.030
I'm going to suggest three different algorithms to you.

00:00:03.030 --> 00:00:06.850
These are all examples of supervised classification algorithms and

00:00:06.850 --> 00:00:08.360
you should pick one.

00:00:08.360 --> 00:00:15.970
Your choices are k nearest neighbors, adaboost and random forest.

00:00:15.970 --> 00:00:17.640
You don't know what any of these are right now,

00:00:17.640 --> 00:00:19.349
of course, but that's sort of the point.

00:00:20.740 --> 00:00:23.660
Here's a tiny bit of information on each one to maybe help you

00:00:23.660 --> 00:00:24.730
start making your decision.

00:00:25.830 --> 00:00:29.130
If you're brand new to machine learning, you've never done it before, or

00:00:29.130 --> 00:00:32.270
it's still kind of a challenge for you to understand the algorithms that

00:00:32.270 --> 00:00:35.800
we've talked about so far, I would suggest trying k nearest neighbors.

00:00:35.800 --> 00:00:37.680
This is a classic algorithm.

00:00:37.680 --> 00:00:40.900
It's very simple and easy to understand, which is a big advantage in

00:00:40.900 --> 00:00:44.060
a machine learning algorithm, that you know what's going on.

00:00:44.060 --> 00:00:46.090
If you're down with everything we've done so far and

00:00:46.090 --> 00:00:50.330
you're ready for a really interesting challenge, I would suggest adaboost or

00:00:50.330 --> 00:00:53.730
random forest, which are both examples of what we call ensemble methods.

00:00:54.800 --> 00:00:58.000
The name ensemble methods gives you a little bit of a hint of what these two

00:00:58.000 --> 00:00:59.270
might be doing.

00:00:59.270 --> 00:01:03.610
They're meta classifiers that are built from many, usually, decision trees, so

00:01:03.610 --> 00:01:05.120
you have many classifiers and

00:01:05.120 --> 00:01:09.140
you sort of have them all working together to come up with a single decision.

00:01:09.140 --> 00:01:12.480
It's a little bit like how we choose the president by voting.

00:01:12.480 --> 00:01:16.220
There's a single decision of who's the president going to be, and there are many

00:01:16.220 --> 00:01:19.780
different people who have different opinions on what that answer should be.

00:01:19.780 --> 00:01:22.620
And so what you have to do is you ask the question of many different people and

00:01:22.620 --> 00:01:25.140
all together you come up with a single answer.

00:01:25.140 --> 00:01:27.240
That's a little bit like what these two algorithms do, but

00:01:27.240 --> 00:01:29.630
they do it in slightly different ways.

00:01:29.630 --> 00:01:32.480
However, any of the algorithms that you pick should all be

00:01:32.480 --> 00:01:36.500
supported in SK-learn so you can rely on SK-learn having something that you can

00:01:36.500 --> 00:01:37.710
use straight out of the box.

