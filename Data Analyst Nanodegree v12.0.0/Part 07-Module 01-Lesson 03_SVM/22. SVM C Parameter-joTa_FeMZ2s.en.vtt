WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:04.059
The other important parameter for an SVM is the C parameter.

00:00:04.059 --> 00:00:05.490
So what does C do?

00:00:05.490 --> 00:00:09.070
It controls the tradeoff between a smooth decision boundary and

00:00:09.070 --> 00:00:11.930
one that classifies all the training points correctly.

00:00:11.930 --> 00:00:14.410
So let's suppose our data looks like this.

00:00:14.410 --> 00:00:17.100
And just like we saw with gamma, there's a number of different,

00:00:17.100 --> 00:00:20.730
completely valid decision boundaries that you can draw in here.

00:00:20.730 --> 00:00:22.930
You could draw something that might be very straight, but

00:00:22.930 --> 00:00:26.210
it comes at the cost of a few points being misclassified.

00:00:26.210 --> 00:00:29.940
You could also draw in something that's considerably more wiggly, but

00:00:29.940 --> 00:00:33.980
where you get potentially all of the training points correct.

00:00:33.980 --> 00:00:36.580
Of course, the tradeoff of having something that's very intricate,

00:00:36.580 --> 00:00:37.660
very complicated like this.

00:00:37.660 --> 00:00:40.920
is that chances are it's not going to generalize quite as

00:00:40.920 --> 00:00:42.200
well to your test set.

00:00:42.200 --> 00:00:43.610
So something that's a little straighter,

00:00:43.610 --> 00:00:47.470
a little bit more straightforward may be actually the better choice once you

00:00:47.470 --> 00:00:50.140
start looking at the accuracy on your test set.

00:00:50.140 --> 00:00:51.670
So here's a quiz for you.

00:00:51.670 --> 00:00:55.360
It's a little bit tricky because you'll have to go to the sklearn documentation

00:00:55.360 --> 00:00:58.020
or potentially to play around with some code on your own to come up

00:00:58.020 --> 00:00:59.110
with the answer.

00:00:59.110 --> 00:01:01.590
And the question is let's say you have a large value of C.

00:01:01.590 --> 00:01:05.390
Does that mean you're going to get a smooth boundary or

00:01:05.390 --> 00:01:07.980
that you'll get more training points correct?

00:01:07.980 --> 00:01:09.410
There's going to be a tradeoff.

00:01:09.410 --> 00:01:12.820
Again to answer this quiz you're going to want to go to Google or

00:01:12.820 --> 00:01:15.480
potentially to the sklearn documentation.

00:01:15.480 --> 00:01:17.150
For those of you who are more adventurous or

00:01:17.150 --> 00:01:19.910
who like to go directly to the code to figure these things out,

00:01:19.910 --> 00:01:23.860
you can certainly play around with some code that will help you visualize this.

00:01:23.860 --> 00:01:26.610
One way you can do that is you can go back to the previous lesson,

00:01:26.610 --> 00:01:30.390
the Naive Bayes lesson where you were drawing some decision boundaries that you

00:01:30.390 --> 00:01:34.140
could actually visualize in the Udacity interpreter.

00:01:34.140 --> 00:01:35.880
And instead of running those with Naive Bayes,

00:01:35.880 --> 00:01:37.770
of course you can just run them with an SVM and

00:01:37.770 --> 00:01:41.470
play around with different values of C and use that to answer the question.

00:01:41.470 --> 00:01:44.630
If you do that, just a pro tip, use the rbf kernel, because this is

00:01:44.630 --> 00:01:48.600
where you'll actually see a big difference based on the value of C that you use.

