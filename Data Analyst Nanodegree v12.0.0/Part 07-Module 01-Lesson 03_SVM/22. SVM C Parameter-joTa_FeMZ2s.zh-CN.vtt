WEBVTT
Kind: captions
Language: zh-CN

00:00:00.260 --> 00:00:04.059
SVM 的另一个重要参数是 C 参数

00:00:04.059 --> 00:00:05.490
C 的作用是什么？

00:00:05.490 --> 00:00:09.070
它会在光滑的决策边界

00:00:09.070 --> 00:00:11.930
以及尽可能正确分类所有训练点两者之间进行平衡

00:00:11.930 --> 00:00:14.410
假设我们的数据是这样的

00:00:14.410 --> 00:00:17.100
和我们在关于 γ 参数那部分看到的一样 你可以画出各种各样

00:00:17.100 --> 00:00:20.730
有效的决策边界

00:00:20.730 --> 00:00:22.930
你可以画出可能是非常直的线

00:00:22.930 --> 00:00:26.210
其代价是有少数的点分类错误

00:00:26.210 --> 00:00:29.940
也可以画出相当曲折的线

00:00:29.940 --> 00:00:33.980
基本上所有的训练点都被分类正确

00:00:33.980 --> 00:00:36.580
当然 选择一个复杂模型是有代价的

00:00:36.580 --> 00:00:37.660
像这样复杂的模型

00:00:37.660 --> 00:00:40.920
可能有一定的概率

00:00:40.920 --> 00:00:42.200
对于测试集的泛化能力不够

00:00:42.200 --> 00:00:43.610
有些会稍微直一些

00:00:43.610 --> 00:00:47.470
稍微更直接些 在开始观察测试集的准确度时

00:00:47.470 --> 00:00:50.140
可能实际上是更好的选择

00:00:50.140 --> 00:00:51.670
现在要你做个测验

00:00:51.670 --> 00:00:55.360
它有点复杂 因为你要到 sklearn 文档中去寻找答案

00:00:55.360 --> 00:00:58.020
或者自己写一些代码

00:00:58.020 --> 00:00:59.110
以便得到答案

00:00:59.110 --> 00:01:01.590
我们的问题是 假设有一个很大的 C 值

00:01:01.590 --> 00:01:05.390
这意味着决策边界会比较光滑

00:01:05.390 --> 00:01:07.980
还是被正确分类的训练点会更多？

00:01:07.980 --> 00:01:09.410
这是一个折中

00:01:09.410 --> 00:01:12.820
同样 要回答这个测验 你可以访问 Google 

00:01:12.820 --> 00:01:15.480
搜索 sklearn 文档

00:01:15.480 --> 00:01:17.150
如果你想更进一步

00:01:17.150 --> 00:01:19.910
或是喜欢直接编写代码来解决问题

00:01:19.910 --> 00:01:23.860
你可以编写一些代码来形象地展现结果

00:01:23.860 --> 00:01:26.610
你可以返回到上一节

00:01:26.610 --> 00:01:30.390
朴素的贝叶斯课程中 画出一些决策边界

00:01:30.390 --> 00:01:34.140
并在优达学城的在线 Python 解释器中进行可视化

00:01:34.140 --> 00:01:35.880
去掉那些朴素贝叶斯的代码

00:01:35.880 --> 00:01:37.770
用 SVM 的代码来运行

00:01:37.770 --> 00:01:41.470
尝试一些不同的 C 值 用来回答这个问题

00:01:41.470 --> 00:01:44.630
如果你这样做 提示一下 请使用径向基函数作为核函数

00:01:44.630 --> 00:01:48.600
这样你就能看出不同的 C 值结果的巨大差别

