WEBVTT
Kind: captions
Language: ja

00:00:00.260 --> 00:00:02.640
先ほど見た分類境界線は

00:00:02.640 --> 00:00:04.840
ひじょ〜に複雑なものでした。

00:00:04.840 --> 00:00:07.360
それではこのような例を考えてみましょう。

00:00:07.360 --> 00:00:10.220
これを私たちは"over-fitting"と呼んでいます。

00:00:10.220 --> 00:00:15.140
機械学習ではよく起きる現象で、あなたも経験するでしょう。

00:00:15.140 --> 00:00:18.700
例を使って説明しましょう。このようなデータがあったとします。

00:00:18.700 --> 00:00:20.660
線形の境界線が引けそうです。

00:00:20.660 --> 00:00:24.770
×と○の境界線がこのようだったらどうでしょう。

00:00:24.770 --> 00:00:30.880
確かに全てのデータを正しく分類できていますが、常軌を逸しています。

00:00:30.880 --> 00:00:32.930
学習用データを適用させる際に厳密すぎると

00:00:32.930 --> 00:00:37.160
機械学習アルゴリズムはこのような複雑な境界線を作ります。

00:00:37.160 --> 00:00:43.430
シンプルな境界線が引けるにも関わらずです。これがover-fittingです。

00:00:43.430 --> 00:00:48.340
機械学習ではこのようなover-fittingが起きることを回避せねばなりません。

00:00:48.340 --> 00:00:51.960
over-fittingを回避するためにできることの一つが

00:00:51.960 --> 00:00:53.110
アルゴリズムのパラメータ調整です。

00:00:53.110 --> 00:00:55.880
SVMのパラメータについては説明をしました。

00:00:55.880 --> 00:00:58.750
Cやgamma、kernelなどを覚えているでしょう。

00:00:58.750 --> 00:01:03.050
SVMのover-fittingに影響を与えるパラメーターはどれでしょうか？

00:01:03.100 --> 00:01:06.440
正しいと思うものを全て選んでください。

