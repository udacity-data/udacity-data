WEBVTT
Kind: captions
Language: zh-CN

00:00:00.080 --> 00:00:03.450
在接下来几个视频中 我将向你展示

00:00:03.450 --> 00:00:06.620
真正应用到人脸识别中的 PCA 的编码示例

00:00:06.620 --> 00:00:10.507
这是从 sklearn 文档的示例摘取并改编的内容 

00:00:10.507 --> 00:00:14.219
而且我会提供原始代码的链接 以便你访问和了解

00:00:14.219 --> 00:00:17.253
接下来 我会带你浏览其中某些最为重要的部分

00:00:17.253 --> 00:00:19.376
该代码要执行的第一个操作是

00:00:19.376 --> 00:00:23.930
导入 10 到 15 年前世界知名领导人的一系列照片

00:00:23.930 --> 00:00:27.530
接下来就是将其分为训练集和测试集

00:00:27.530 --> 00:00:31.280
很好 但接下来此处的这一块就是由 PCA 发挥作用

00:00:31.280 --> 00:00:34.380
通过该示例 你会发现 PCA 在应用到人脸识别时

00:00:34.380 --> 00:00:37.880
有时在文献中也被称作特征脸

00:00:37.880 --> 00:00:41.230
在该行 我们发现正在创建的 PCA

00:00:41.230 --> 00:00:44.020
它在 sklearn 中被称作 RandomizedPCA

00:00:44.020 --> 00:00:46.700
然后 它还会被调整到训练数据中

00:00:46.700 --> 00:00:49.850
此处该行的作用是要求提供特征脸

00:00:49.850 --> 00:00:53.320
特征脸基本上就是人脸数据的主成分

00:00:53.320 --> 00:00:56.220
因此它会接受 PCA 成分 然后对其进行重塑

00:00:56.220 --> 00:00:58.340
这是因为 现在这些成分还只是数字字符串

00:00:58.340 --> 00:01:03.250
需要将其转变回方形 使其看起来像照片

00:01:03.250 --> 00:01:07.168
你还会发现 该示例中正在使用的主成分的

00:01:07.168 --> 00:01:08.443
数量为 150

00:01:08.443 --> 00:01:12.348
如果你研究 sklearn 文档页面上的示例代码

00:01:12.348 --> 00:01:16.692
你会发现这些照片的原始维数超过 1,800

00:01:16.692 --> 00:01:19.716
也就是说 我们将 1,800 个特征减少至 150 个

00:01:19.716 --> 00:01:21.800
压缩率超过 10:1

00:01:21.800 --> 00:01:25.410
我使用 PCA 进行的最后一项操作就是转换数据

00:01:25.410 --> 00:01:26.870
当我执行调整命令时

00:01:26.870 --> 00:01:29.435
我只是探究有哪些主成分

00:01:29.435 --> 00:01:32.640
我正是通过这些转换命令获得了我的数据 

00:01:32.640 --> 00:01:35.110
并将其转换成主成分表示法

00:01:35.110 --> 00:01:37.830
该代码的剩余工作就是创建 SVM

00:01:37.830 --> 00:01:40.270
请注意 SVC 是其在 sklearn 中的叫法 

00:01:40.270 --> 00:01:41.970
即支持向量分类器

00:01:41.970 --> 00:01:45.080
在这里 它们会巧妙地弄清楚

00:01:45.080 --> 00:01:49.140
它们要使用的支持向量机的参数

00:01:49.140 --> 00:01:51.480
然后它们会将主成分作为特征

00:01:51.480 --> 00:01:55.770
尝试在测试集中识别提供的照片中显示的人的身份

00:01:55.770 --> 00:01:58.240
现在 我向你展示运行该代码时产生的效果

00:01:58.240 --> 00:01:59.990
它要做的第一件事是打印文档字符串

00:01:59.990 --> 00:02:01.460
只是告诉我进行的操作

00:02:01.460 --> 00:02:02.530
然后是某些有关数据集的信息

00:02:02.530 --> 00:02:04.420
因此 我有 1,288 个样本

00:02:04.420 --> 00:02:09.060
以及输入特征空间中可供我使用的 1,850 个特征

00:02:09.060 --> 00:02:10.740
现在显示七个不同的人

00:02:10.740 --> 00:02:14.940
然后我们使用训练集中 966 张人脸的 150 个特征脸进行识别

00:02:14.940 --> 00:02:18.320
接下来会显示数据集中人的列表以及

00:02:18.320 --> 00:02:19.780
我们正确确认其身份的频率

00:02:19.780 --> 00:02:23.130
查准率、查全率、F1 分数和支持是与其评估矩阵 (查准率)

00:02:23.130 --> 00:02:25.680
息息相关的因素

00:02:25.680 --> 00:02:28.170
我们将在接下来的课程中深入探讨

00:02:28.170 --> 00:02:31.670
你会发现 总的来说还是提高了正确率

00:02:31.670 --> 00:02:33.880
从大约 60% 提高到几乎 90%

00:02:33.880 --> 00:02:38.350
因此 尽管我们将维数降低到十分之一

00:02:38.350 --> 00:02:40.370
我们仍能够取得好成绩

00:02:40.370 --> 00:02:43.100
该示例另一项让我很欣赏的功能是

00:02:43.100 --> 00:02:45.460
它们实际上会显示特征脸

00:02:45.460 --> 00:02:47.580
这是我们数据的第一个主成分

00:02:47.580 --> 00:02:50.180
这是第二个 第三个

00:02:50.180 --> 00:02:53.670
该图片表示它在所有数据中发现的

00:02:53.670 --> 00:02:55.800
最大差别

00:02:55.800 --> 00:02:58.830
在该示例中 要想准确地了解其意义有点困难

00:02:58.830 --> 00:03:01.020
如果换成说两眼之间的距离

00:03:01.020 --> 00:03:05.920
或是否戴眼镜 则更为容易理解一些

00:03:05.920 --> 00:03:08.990
相反 我们收到的是这种重像

00:03:08.990 --> 00:03:13.838
但在 SVM 中将这些合成图像用作特征

00:03:13.838 --> 00:03:17.832
在预测图片中脸的身份时非常有用

00:03:17.832 --> 00:03:18.380
最后但同样重要的是

00:03:18.380 --> 00:03:22.130
你会收到打印材料 其中提供 12 张代表性的脸

00:03:22.130 --> 00:03:25.010
然后 这些算法尽力猜测出其身份并提供正确答案

00:03:25.010 --> 00:03:27.100
你会发现这些算法通常会猜测错误

00:03:27.100 --> 00:03:30.900
我想这里这个是托尼·布莱尔 但其实是小布什

00:03:30.900 --> 00:03:33.010
但大部分照片都猜对了 很好

