WEBVTT
Kind: captions
Language: en

00:00:00.070 --> 00:00:02.690
So now that we know that we have potentially a large number of

00:00:02.690 --> 00:00:05.590
measurable features, but maybe a small number of

00:00:05.590 --> 00:00:08.840
underlying latent features that contain most of the information.

00:00:08.840 --> 00:00:11.490
My question is what we'll be exploring in this lesson.

00:00:11.490 --> 00:00:15.290
What's the best way to condense our four features to two?

00:00:15.290 --> 00:00:17.250
So that we really get to the heart of the information.

00:00:17.250 --> 00:00:19.600
So we're really probing the size and the neighborhood.

00:00:19.600 --> 00:00:22.130
One way to get at this is just with simple feature selection,

00:00:22.130 --> 00:00:23.610
like with the last lesson.

00:00:23.610 --> 00:00:27.230
And if you put these four features into a feature selection tool,

00:00:27.230 --> 00:00:32.000
maybe it would keep the square footage, but throw out the number of rooms.

00:00:32.000 --> 00:00:35.760
Maybe it would keep the safety and ignore the school ranking.

00:00:35.760 --> 00:00:37.530
So here's a little practice quiz.

00:00:37.530 --> 00:00:40.380
Which of the feature selection tools do you think would be most

00:00:40.380 --> 00:00:41.260
suitable for this?

00:00:41.260 --> 00:00:44.410
These are two examples that are both available in sklearn.

00:00:44.410 --> 00:00:46.670
Select percentile you're already familiar with,

00:00:46.670 --> 00:00:49.690
it just selects the top X percent where you're allowed to

00:00:49.690 --> 00:00:52.520
specify the percentage of features that you want to keep.

00:00:52.520 --> 00:00:55.770
Another option is SelectKBest and this one's fairly straightforward.

00:00:55.770 --> 00:00:59.470
What you do as one of the arguments you specify what k is.

00:00:59.470 --> 00:01:01.750
That's the number of features that you want to keep.

00:01:01.750 --> 00:01:05.489
So if you put in 10 for k it's going to take the ten best features.

00:01:05.489 --> 00:01:08.650
And just to make you think about this a little bit more let me get rid

00:01:08.650 --> 00:01:11.660
of the knowledge that we already have for features.

00:01:11.660 --> 00:01:13.840
Let's suppose that the number of features you have available to

00:01:13.840 --> 00:01:16.320
you isn't something that you know very well.

00:01:16.320 --> 00:01:18.630
Say it's one of the first times you're looking at this data set.

00:01:18.630 --> 00:01:20.610
But you do know that the size and

00:01:20.610 --> 00:01:24.450
the neighborhood are going to be underlying latent variables that are sort of

00:01:24.450 --> 00:01:27.940
driving the trends in, in all of the features that you have available to you.

00:01:27.940 --> 00:01:31.490
So the question for you is, if you want to have two output features,

00:01:31.490 --> 00:01:35.240
what's the most suitable feature selection tool to use in this scenario?

00:01:35.240 --> 00:01:37.770
Do you want to use SelectKBest or SelectPercentile?

