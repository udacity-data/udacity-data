WEBVTT
Kind: captions
Language: zh-CN

00:00:00.200 --> 00:00:04.780
现在您应该对 PCA 及其使用方法有了直观的认识。

00:00:04.780 --> 00:00:07.600
我很快将向您提供最后一个示例，

00:00:07.600 --> 00:00:11.830
该示例是在开放情况下应用 PCA 的最佳示例之一。

00:00:11.830 --> 00:00:14.260
进入该示例前，我们暂停一下并

00:00:14.260 --> 00:00:15.990
讨论您想要何时使用 PCA。

00:00:16.990 --> 00:00:19.330
何时适合使用该方法？

00:00:19.330 --> 00:00:23.460
第一种情况是如果您想要访问隐藏的特征，而这些特征您认为可能

00:00:23.460 --> 00:00:25.540
显示在您的数据中的图案中。

00:00:25.540 --> 00:00:28.370
您要尝试做的所有工作可能就是确定是否存在

00:00:28.370 --> 00:00:30.010
隐藏的特征。

00:00:30.010 --> 00:00:33.480
换句话说您只是想知道第一个主成分的大小。

00:00:33.480 --> 00:00:35.270
这种情况的示例就是

00:00:35.270 --> 00:00:38.240
是否可以估量出 Enron 的大亨是谁。

00:00:38.240 --> 00:00:41.240
第二种情况当然就是降维。

00:00:41.240 --> 00:00:44.570
PCA 可以执行许多工作，能在该方面为您提供帮助。

00:00:44.570 --> 00:00:48.300
第一项是它可以帮助您可视化高维数据。

00:00:48.300 --> 00:00:51.914
当然，当您要画散点图时，您只有

00:00:51.914 --> 00:00:55.598
两个维度可用，但很多情况下您都有超过两个特征。

00:00:55.598 --> 00:00:58.997
还有一个难题就是如何在只有两个维度的情况下

00:00:58.997 --> 00:01:03.200
画出能够表示数据点的三个、四个或更多特征。

00:01:04.290 --> 00:01:07.157
那么您能做的就是将其投射到前两个

00:01:07.157 --> 00:01:11.070
主成分，然后只要标绘并画出散点图。

00:01:11.070 --> 00:01:14.270
然后像 k-means 集群这种算法就更容易

00:01:14.270 --> 00:01:15.620
可视化了。

00:01:15.620 --> 00:01:18.410
您还在捕获数据中的大部分信息，而现在

00:01:18.410 --> 00:01:21.280
您可以通过这两个维度将其画下来。

00:01:21.280 --> 00:01:22.870
PCA 可以提供帮助的另一方面是您

00:01:22.870 --> 00:01:24.940
怀疑数据中存在噪音的情况。

00:01:24.940 --> 00:01:27.380
几乎在所有数据中都存在噪音。

00:01:27.380 --> 00:01:30.900
希望第一个或第二个，也就是您最强大的主成分

00:01:30.900 --> 00:01:32.830
捕获数据中真正的模式。

00:01:32.830 --> 00:01:36.010
而较小的主成分只表示

00:01:36.010 --> 00:01:38.380
这些模式的噪音变体。

00:01:38.380 --> 00:01:41.460
因此通过抛弃重要性较低的主成分，

00:01:41.460 --> 00:01:42.399
您可以处理到这些噪音。

00:01:43.440 --> 00:01:47.020
最后一种，也是我们将用作剩余课程示例的情况

00:01:47.020 --> 00:01:50.920
是在使用另一个算法前使用 PCA 进行预处理，也就是

00:01:50.920 --> 00:01:53.160
归纳或分类任务。

00:01:53.160 --> 00:01:55.940
如您所知，如果您有很高的维数，而且

00:01:55.940 --> 00:01:59.710
如果您有复杂的，比如分类算法，

00:01:59.710 --> 00:02:01.760
则算法的方差非常高，

00:02:01.760 --> 00:02:04.360
最终会被数据中的噪音同化，

00:02:04.360 --> 00:02:05.800
导致运行非常慢。

00:02:05.800 --> 00:02:08.740
如果您的输入使用这些算法且维数很高，则会

00:02:08.740 --> 00:02:10.639
出现很多情况。

00:02:10.639 --> 00:02:13.660
但当然，该算法针对手头的问题可能比较有效。

00:02:13.660 --> 00:02:17.470
因此您可以执行的操作之一就是使用 PCA 降低

00:02:17.470 --> 00:02:18.840
输入特征的维数。

00:02:18.840 --> 00:02:21.830
这样，您的分类算法可以更好地发挥作用。

00:02:22.960 --> 00:02:25.030
此为我们接下来要进行的操作示例。

00:02:25.030 --> 00:02:27.320
那就是特征脸，这是

00:02:27.320 --> 00:02:30.790
一种将 PCA 应用于人的照片的方法。

00:02:30.790 --> 00:02:34.930
因此这是一个非常高维数的控件，您的照片中

00:02:34.930 --> 00:02:36.610
有许多像素。

00:02:36.610 --> 00:02:39.890
但如果您要识别图片中拍摄的人的身份，

00:02:39.890 --> 00:02:43.700
那么就是在运行某种人脸识别，或识别照片内容，

00:02:43.700 --> 00:02:47.550
那么使用 PCA 可以将非常高的输入维数降低至

00:02:47.550 --> 00:02:50.190
可能是原来的十分之一。

00:02:50.190 --> 00:02:53.930
将其填入 SVM，然后进行真正的识别，

00:02:53.930 --> 00:02:55.670
尝试发现被拍摄人的身份。

00:02:55.670 --> 00:02:57.870
现在输入的内容不是最初的像素或

00:02:57.870 --> 00:03:00.840
图片，而是主成分。

00:03:00.840 --> 00:03:02.850
我向您展示该示例，您就会明白我的意思了。

