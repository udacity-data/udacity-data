WEBVTT
Kind: captions
Language: ar

00:00:00.080 --> 00:00:03.450
‫والآن سوف أعرض لكم في مقاطع الفيديو القليلة القادمة مثالاً مبرمجًا بالفعل

00:00:03.450 --> 00:00:06.620
‫على PCA كما هو مطبق في التعرف على الوجه.

00:00:06.620 --> 00:00:10.507
‫وهذا مأخوذ ومستوحى من مثال موجود في وثائق scikit learn،

00:00:10.507 --> 00:00:14.219
‫لذا سوف أضع في التعليقات رابطًا للتعليمة البرمجية الأصلية كي تلقوا عليها نظرة،

00:00:14.219 --> 00:00:17.253
‫ولكنني أريد أن أشرح لكم بالتفصيل بعضًا من أهم النقاط.

00:00:17.253 --> 00:00:19.376
‫إن أول شيء تقوم به التعليمة البرمجية هو

00:00:19.376 --> 00:00:23.930
‫استيراد مجموعة من الصور لقادة عالميين مشهورين من حوالي 10 إلى 15 سنة.

00:00:23.930 --> 00:00:27.530
‫ثم تقوم بعد ذلك بتقسيم تلك الصور إلى مجموعة تدريب ومجموعة اختبار.

00:00:27.530 --> 00:00:31.280
‫رائع جدًا، ولكن هذه الكتلة هنا هي التي يحدث من خلالها تحليل PCA فعليًا.

00:00:31.280 --> 00:00:34.380
‫سترون في هذا المثال، وأحيانًا في الكتابات المتعلقة بهذا الموضوع، أن PCA

00:00:34.380 --> 00:00:37.880
‫يسمى أيضًا eigenfaces عند تطبيقه على التعرف على الوجه.

00:00:37.880 --> 00:00:41.230
‫هنا في هذا السطر نرى أنه يتم إنشاء تحليل PCA،

00:00:41.230 --> 00:00:44.020
‫ويسمى RandomizedPCA في scikit-learn.

00:00:44.020 --> 00:00:46.700
‫ثم بعد ذلك تتم أيضًا ملاءمته إلى بيانات التدريب.

00:00:46.700 --> 00:00:49.850
‫ثم ما يفعله هذا السطر هنا هو أنه يطلب قيم eigenfaces.

00:00:49.850 --> 00:00:53.320
‫وقيم eigenfaces هي في الأساس المكونات الرئيسية لبيانات الوجه.

00:00:53.320 --> 00:00:56.220
‫لذا فإنه يأخذ pca.components، ثم يقوم بإعادة تشكيلها.

00:00:56.220 --> 00:00:58.340
‫لأنها الآن عبارة عن مجرد سلاسل من الأرقام

00:00:58.340 --> 00:01:03.250
‫وهو يريد إعادة تحويلها إلى مربعات حتى تبدو مثل الصور.

00:01:03.250 --> 00:01:07.168
‫وكما ترون أيضًا، فإن عدد المكونات الرئيسية المستخدمة في

00:01:07.168 --> 00:01:08.443
‫هذا المثال هو 150.

00:01:08.443 --> 00:01:12.348
‫وإذا نظرتم إلى التعليمة البرمجية المثال الموجودة على صفحة وثائق scikit-learn،

00:01:12.348 --> 00:01:16.692
‫فستجدون أن عدد الأبعاد الأصلية لهذه الصور يتعدى 1800.

00:01:16.692 --> 00:01:19.716
‫لذا فقد انخفض عدد الميزات من 1800 إلى 150،

00:01:19.716 --> 00:01:21.800
‫وهو عامل ضغط لأكثر من 10 أضعاف.

00:01:21.800 --> 00:01:25.410
‫وآخر ما سأقوم به بواسطة PCA هو تحويل البيانات الموجودة لدي.

00:01:25.410 --> 00:01:26.870
‫وعندما أجري أمر الملاءمة،

00:01:26.870 --> 00:01:29.435
‫فأنا أقوم بمجرد اكتشاف المكونات الرئيسية.

00:01:29.435 --> 00:01:32.640
‫وأوامر التحويل هذه هي التي أقوم من خلالها بأخذ البيانات الموجودة لدي

00:01:32.640 --> 00:01:35.110
‫وتحويلها إلى تمثيل المكونات الرئيسية.

00:01:35.110 --> 00:01:37.830
‫أما الأسطر المتبقية من هذه التعليمة البرمجية فهي مسئولة عن إنشاء SVM.

00:01:37.830 --> 00:01:40.270
‫تذكروا أن ذلك يسمى SVC في scikit-learn،

00:01:40.270 --> 00:01:41.970
‫أي مصنف متجهات الدعم.

00:01:41.970 --> 00:01:45.080
‫وهي تقوم ببعض عمليات التحويل المذهلة لمعرفة أيٍ من معلمات

00:01:45.080 --> 00:01:49.140
‫جهاز متجهات الدعم التي تريد استخدامها على وجه التحديد.

00:01:49.140 --> 00:01:51.480
‫وباستخدام المكونات الرئيسية كميزات،

00:01:51.480 --> 00:01:55.770
‫تحاول في الاختبارات التعرف على الشخص الذي يظهر في صورة محددة.

00:01:55.770 --> 00:01:58.240
‫والآن، سأريكم كيف يبدو الأمر عندما أقوم بتنفيذ هذه التعليمة البرمجية.

00:01:58.240 --> 00:01:59.990
‫أول ما تقوم به هو إدخال سلسلة doc،

00:01:59.990 --> 00:02:01.460
‫لمجرد إطلاعنا على ما يجري.

00:02:01.460 --> 00:02:02.530
‫ثم تعطينا بعض المعلومات حول مجموعة البيانات.

00:02:02.530 --> 00:02:04.420
‫إذن، لدينا 1288 عينة،

00:02:04.420 --> 00:02:09.060
‫تحتوي على 1850 ميزة متاحة لنا في فضاء ميزات الإدخال.

00:02:09.060 --> 00:02:10.740
‫ويظهر سبعة أشخاص مختلفين

00:02:10.740 --> 00:02:14.940
‫ثم نستخدم 150 eigenfaces من ضمن 966 وجهًا موجودًا لدينا في مجموعة التدريب.

00:02:14.940 --> 00:02:18.320
‫ما يظهر لنا بعد ذلك هو قائمة بالأشخاص الموجودين في مجموعة البيانات الخاصة بنا،

00:02:18.320 --> 00:02:19.780
‫وعدد مرات التعرف عليهم بشكل صحيح.

00:02:19.780 --> 00:02:23.130
‫Precision وrecall وf1-score وsupport هي أمور تتعلق إلى حدٍ ما

00:02:23.130 --> 00:02:25.680
‫بالدقة، وقياسات التقييم الخاصة بهذه الأمور.

00:02:25.680 --> 00:02:28.170
‫وسنتحدث كثيرًا عنها في درس قادم.

00:02:28.170 --> 00:02:31.670
‫وكما ترون، فإنها تفهم الأمور بطريقة صحيحة بصفة عامة.

00:02:31.670 --> 00:02:33.880
‫بنسبة 60 إلى 90% من عدد المرات.

00:02:33.880 --> 00:02:38.350
‫ومع أننا قمنا بتقليل الأبعاد بعشرة أضعاف،

00:02:38.350 --> 00:02:40.370
‫فما زلنا نحصل على أداء جيد.

00:02:40.370 --> 00:02:43.100
‫أحد الأمور الرائعة حقًا والتي تعجبني بخصوص هذا المثال أنه

00:02:43.100 --> 00:02:45.460
‫يعرض لنا بالفعل وجوه eigen.

00:02:45.460 --> 00:02:47.580
‫فهذا هو المكون الرئيسي الأول للبيانات،

00:02:47.580 --> 00:02:50.180
‫وهذا هو المكون الرئيسي الثاني، وهذا هو الثالث.

00:02:50.180 --> 00:02:53.670
‫إذن تمثل هذه الصورة أقصى تباين

00:02:53.670 --> 00:02:55.800
‫يراه في البيانات بأكملها.

00:02:55.800 --> 00:02:58.830
‫ويصعب قليلاً فهم ما يعنيه ذلك بالضبط في هذا المثال.

00:02:58.830 --> 00:03:01.020
‫وسيكون من الأفضل لو أخبرنا بأمر مثل،

00:03:01.020 --> 00:03:05.920
‫المسافة بين العينين، أو ما إذا كان الشخص يرتدي نظارات أم لا.

00:03:05.920 --> 00:03:08.990
‫ولكن ما نحصل عليه بدلاً من ذلك هو هذه الصور التي تبدو مثل الأطياف.

00:03:08.990 --> 00:03:13.838
‫إلا أنه باستخدام هذه الصور المركبة معًا كميزات في SVM،

00:03:13.838 --> 00:03:17.832
‫يمكنها أن تكون فعالة جدًا في التنبؤ بالشخص الذي يظهر لنا وجهه.

00:03:17.832 --> 00:03:18.380
‫وأخيرًا وليس آخرًا،

00:03:18.380 --> 00:03:22.130
‫لدينا هذه المطبوعة الصغيرة التي تعرض لنا 12 وجهًا تمثيليًا

00:03:22.130 --> 00:03:25.010
‫وأفضل تخمين تتوصل له الخوارزمية بشأن أصحاب هذه الوجوه، والإجابة الفعلية.

00:03:25.010 --> 00:03:27.100
‫وكما ترون، فأنها لا تخمنها بصورة صحيحة دائمًا.

00:03:27.100 --> 00:03:30.900
‫فهذا الوجه هنا تعتقد الخوارزمية أنه لـTony Blair، ولكنه في الواقع وجه George W Bush،

00:03:30.900 --> 00:03:33.010
‫ولكن بالنسبة لمعظم الوجوه، فقد خمنتها بصورة صحيحة، وهذا رائع جدًا.

