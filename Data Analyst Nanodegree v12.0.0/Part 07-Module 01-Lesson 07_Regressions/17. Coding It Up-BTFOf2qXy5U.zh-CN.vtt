WEBVTT
Kind: captions
Language: zh-CN

00:00:00.420 --> 00:00:04.370
现在 欢迎学习回归课程的编码部分

00:00:04.370 --> 00:00:09.920
像以前一样 我们还是从 Google 开始 看看搜索 sklearn 会出现哪些内容

00:00:09.920 --> 00:00:12.380
你可以看到 出现了很多结果

00:00:12.380 --> 00:00:15.880
这个线性回归就是我们最终将使用的方法

00:00:15.880 --> 00:00:20.080
但实际上 我认为从这个链接开始更好

00:00:20.080 --> 00:00:23.900
因为它更加详细地介绍了广义线性模型

00:00:23.900 --> 00:00:27.810
那么这里有一个公式 它有点难以解释

00:00:27.810 --> 00:00:31.480
但它是对 y 等于 mx 加 b 的改写

00:00:31.480 --> 00:00:35.720
只不过我们现在可以有多个 x

00:00:35.720 --> 00:00:37.930
我们将在课程稍后时间详细介绍此公式

00:00:37.930 --> 00:00:40.280
但是它至少告诉我们

00:00:40.280 --> 00:00:43.510
我们在查找线性形式内容的正确位置

00:00:43.510 --> 00:00:47.470
向下滚动一点 我看到了一个叫做普通最小二乘法的内容

00:00:47.470 --> 00:00:48.360
该代码的准确名称是线性回归

00:00:48.360 --> 00:00:52.740
这看起来正是我想要的

00:00:52.740 --> 00:00:54.750
我有多个点

00:00:54.750 --> 00:00:56.620
通过一条线拟合它们

00:00:56.620 --> 00:01:00.400
更好的是 这里有一些能让我开始操作的示例代码

00:01:00.400 --> 00:01:04.400
希望你认识到 

00:01:04.400 --> 00:01:07.760
这里的代码与我们在监督分类器中看到的代码类型并没有什么差别

00:01:07.760 --> 00:01:10.220
所以 这意味着我们要从 from ... import ... 语句开始

00:01:10.220 --> 00:01:13.028
from sklearn import linear_model

00:01:13.028 --> 00:01:17.980
在 linear_model 内 有一个名为 linearRegression 的对象

00:01:17.980 --> 00:01:20.260
我们会使用它来创建分类器

00:01:20.260 --> 00:01:22.480
接下来 我们要拟合分类器

00:01:22.480 --> 00:01:23.800
在这里

00:01:23.800 --> 00:01:27.540
它们不会使用它进行预测 但我们将会进行预测

00:01:27.540 --> 00:01:30.900
它们会在这里读取系数

00:01:30.900 --> 00:01:32.990
我们称之为斜率

00:01:32.990 --> 00:01:36.860
再向下滚动一点 我看到这里有一个更详细的示例

00:01:36.860 --> 00:01:38.830
如果我在任何阶段遇到困难 都可以使用它来获得帮助

00:01:40.140 --> 00:01:42.940
但事实上 这些信息足以让我们顺利执行操作

