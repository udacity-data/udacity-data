WEBVTT
Kind: captions
Language: en

00:00:00.310 --> 00:00:02.170
I told you that this was a really tricky quiz.

00:00:02.170 --> 00:00:04.550
So if you got it right, good job.

00:00:04.550 --> 00:00:07.250
Let's walk through the answers one at a time.

00:00:07.250 --> 00:00:10.220
The first possibility that you minimize the error on the first and

00:00:10.220 --> 00:00:13.970
the last data points isn't a bad thing to be keeping in mind.

00:00:13.970 --> 00:00:17.580
You certainly want to have a good fit to the first and last data points.

00:00:17.580 --> 00:00:20.000
But you could easily end up with something like this.

00:00:20.000 --> 00:00:23.300
Where the trend of the data as a whole, may look like this.

00:00:23.300 --> 00:00:25.150
But if you're only basing it on the first and

00:00:25.150 --> 00:00:28.250
last points, you would ignore all the data in between and

00:00:28.250 --> 00:00:32.000
come up with something that isn't fitting the pattern as a whole.

00:00:32.000 --> 00:00:32.900
The next choice,

00:00:32.900 --> 00:00:37.910
the sum of the error on all the data points might have sounded like a good idea.

00:00:37.910 --> 00:00:40.250
But here's one place that it can go wrong.

00:00:40.250 --> 00:00:43.200
Suppose you have really lovely linear data like this.

00:00:43.200 --> 00:00:45.010
But you fit it with a regression that looks like this.

00:00:46.510 --> 00:00:48.250
Clearly not a very good fit.

00:00:48.250 --> 00:00:51.990
However, if this error is, let's say negative 100.

00:00:51.990 --> 00:00:55.360
And this error is positive 100.

00:00:55.360 --> 00:00:59.060
Then these two will cancel each other out.

00:00:59.060 --> 00:01:01.170
And likewise for this point.

00:01:01.170 --> 00:01:03.640
This point, this point, and this point.

00:01:05.200 --> 00:01:08.990
So, the sum of the error in this case,

00:01:08.990 --> 00:01:12.340
will actually be zero even though it's a terrible fit.

00:01:12.340 --> 00:01:14.680
That's why we usually don't use the sum of the errors.

00:01:16.500 --> 00:01:18.260
Two things that will work a little bit better,

00:01:18.260 --> 00:01:21.610
will be the sum of the absolute value of the error.

00:01:21.610 --> 00:01:24.299
So, in this case what would happen is we will turn all of these

00:01:25.660 --> 00:01:27.920
into positive errors.

00:01:27.920 --> 00:01:32.760
These three points right here and then these were already positive.

00:01:32.760 --> 00:01:33.520
So all together,

00:01:33.520 --> 00:01:38.140
the sums of the absolute values of the errors will be quite large.

00:01:38.140 --> 00:01:39.370
So that would probably work.

00:01:39.370 --> 00:01:43.810
And the last thing that will work, and that we'll explore in more detail,

00:01:43.810 --> 00:01:47.730
this is actually how linear regressions are calculated,

00:01:47.730 --> 00:01:52.100
is by minimizing the sum of the squared error on all the data points.

00:01:52.100 --> 00:01:54.990
This has the advantages that you get with the absolute value of

00:01:54.990 --> 00:01:58.390
the error because even if you have an error that's negative.

00:01:58.390 --> 00:02:01.130
When you square it, it becomes positive, and of course,

00:02:01.130 --> 00:02:04.610
if it's positive to begin with, it'll still be positive after you square it.

00:02:04.610 --> 00:02:05.560
So, this will work as well.

