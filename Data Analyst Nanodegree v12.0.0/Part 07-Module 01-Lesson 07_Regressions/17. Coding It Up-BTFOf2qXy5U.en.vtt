WEBVTT
Kind: captions
Language: en

00:00:00.420 --> 00:00:04.370
Welcome now to the coding portion of the regression lesson.

00:00:04.370 --> 00:00:09.920
We start, as always, on Google and we look for what sklearn has to offer us.

00:00:09.920 --> 00:00:12.380
As you can see, there's plenty going on here.

00:00:12.380 --> 00:00:15.880
This linear regression is what we'll end up using eventually.

00:00:15.880 --> 00:00:20.080
But I actually think this link is a better one to start at because it

00:00:20.080 --> 00:00:23.900
gives us a little bit more of an introduction to generalized linear models.

00:00:23.900 --> 00:00:27.810
So we have here a formula that, it's a little bit hard to tell, but

00:00:27.810 --> 00:00:31.480
this is just rewriting y equals mx plus b, but

00:00:31.480 --> 00:00:35.720
now we can have more than one x available to us.

00:00:35.720 --> 00:00:37.930
We'll get into this a little bit later in the lesson right now,

00:00:37.930 --> 00:00:40.280
but at least this tells us that we're in the right place for

00:00:40.280 --> 00:00:43.510
something that has a linear form to it.

00:00:43.510 --> 00:00:47.470
Scrolling down a little bit, I see something called ordinary least squares.

00:00:47.470 --> 00:00:48.360
The exact name for

00:00:48.360 --> 00:00:52.740
the code is linear regression, and this looks like exactly what I want.

00:00:52.740 --> 00:00:54.750
I have a variety of points.

00:00:54.750 --> 00:00:56.620
I'm fitting them with a line.

00:00:56.620 --> 00:01:00.400
And maybe even better, I have some example code that can get me started.

00:01:00.400 --> 00:01:04.400
I hope you recognize that the code here really isn't all that different

00:01:04.400 --> 00:01:07.760
from the types of codes that we were seeing for the supervised classifiers.

00:01:07.760 --> 00:01:10.220
So that means that we start with an import statement,

00:01:10.220 --> 00:01:13.028
from sklearn import linear_model.

00:01:13.028 --> 00:01:17.980
Within linear_model, there's an object called linearRegression and

00:01:17.980 --> 00:01:20.260
we use that to create our classifier.

00:01:20.260 --> 00:01:22.480
The next thing that we do is we fit our classifier.

00:01:22.480 --> 00:01:23.800
And then here,

00:01:23.800 --> 00:01:27.540
they're not making predictions with it, although we'll be doing that as well.

00:01:27.540 --> 00:01:30.900
What they're doing here is they're reading out the coefficients, or

00:01:30.900 --> 00:01:32.990
what we called the slope.

00:01:32.990 --> 00:01:36.860
Scrolling down a little further, I see that there's a more detailed example here

00:01:36.860 --> 00:01:38.830
that I could use to help me if I get stuck anywhere.

00:01:40.140 --> 00:01:42.940
But as it happens, this is going to be enough to get us off the ground.

