WEBVTT
Kind: captions
Language: ja

00:00:00.320 --> 00:00:03.945
なぜこれがNaiveBayesと呼ばれているか、少し説明させてください。

00:00:03.945 --> 00:00:08.020
私たちは先ほど「不明な概念が存在する」と言いました。

00:00:08.020 --> 00:00:09.690
これらが分類したい label だとしましょう。

00:00:09.690 --> 00:00:12.180
label A と label B です。

00:00:12.180 --> 00:00:14.350
でもあなたには、label は見えていません。

00:00:14.350 --> 00:00:15.800
隠されています。

00:00:15.840 --> 00:00:18.710
supervised learningにおいては、いつもこの状態から始まります。

00:00:18.710 --> 00:00:21.110
そして label の代わりに見えるものがあります。

00:00:21.110 --> 00:00:22.820
これらの振る舞いです。

00:00:22.820 --> 00:00:24.890
先ほどの例で言えば、クリスやサラが使った単語です。

00:00:24.890 --> 00:00:26.960
もし、彼らが全く同じ頻度で単語を使っていたら

00:00:26.960 --> 00:00:29.970
labelを見抜くことはできないでしょう。

00:00:29.970 --> 00:00:32.384
しかし、もし異なる頻度で単語を使い、

00:00:32.384 --> 00:00:34.764
その数がたくさん、100とか1000になればどうでしょう。

00:00:34.764 --> 00:00:38.224
例えばここにあるような一つの単語が

00:00:38.224 --> 00:00:42.910
人物Aや人物Bを指し示す、痕跡になります。

00:00:42.910 --> 00:00:47.410
そしてすべての単語が示す痕跡を、掛け合せれば良いのです。

00:00:47.410 --> 00:00:50.230
非常に長い文書があったとします。

00:00:50.230 --> 00:00:53.670
人物Aの書いたものと人物Bの書いたものとがあります。

00:00:53.670 --> 00:00:57.460
事前確率と文書から推定される事後確率を掛け算することで

00:00:57.460 --> 00:01:02.210
文書を書いたのが人物Aか人物Bか、確率を求めることができます。

00:01:02.210 --> 00:01:04.650
これがNayveBayesです。

00:01:04.650 --> 00:01:08.970
文書から、その label がこちらである確率が高いか

00:01:08.970 --> 00:01:11.070
それとも、こちらの確率が高いか特定できます。

00:01:11.070 --> 00:01:15.060
これを作者にも適用できます。新しい文書があったとして

00:01:15.060 --> 00:01:20.620
それがシェークスピアのものか他の誰かのものか、推定することができます。

00:01:20.640 --> 00:01:26.550
これは大変強力なツールで、機械学習の多くの分野で適用できます。

00:01:26.550 --> 00:01:29.610
そして、これがNaiveBayesと呼ばれる理由は

00:01:29.610 --> 00:01:35.200
文書の特徴の内、あるものを無視するからです。それはどれかわかりますか？

00:01:35.200 --> 00:01:37.960
一つ、文書の中の個々の単語

00:01:37.990 --> 00:01:40.700
一つ、単語の並び

00:01:40.700 --> 00:01:42.600
一つ、文書の長さ

00:01:42.600 --> 00:01:45.550
通常無視されるものはどれでしょうか？

