WEBVTT
Kind: captions
Language: zh-CN

00:00:00.320 --> 00:00:03.945
让我来跟你们解释一下为什么叫做朴素贝叶斯

00:00:03.945 --> 00:00:07.140
我们所做的就是我们所说的 未知的概念

00:00:07.140 --> 00:00:08.470
这些是我们的目标标签

00:00:08.470 --> 00:00:11.210
我们叫它们标签 A 和标签 B

00:00:12.330 --> 00:00:14.160
而你无法看到它们

00:00:14.160 --> 00:00:14.660
因为它们藏起来了

00:00:15.840 --> 00:00:18.710
跟平常监督学习中的情况一样

00:00:18.710 --> 00:00:21.110
你将要看到的是

00:00:21.110 --> 00:00:22.820
他们所做的事情

00:00:22.820 --> 00:00:24.890
比如他们所使用的词语

00:00:24.890 --> 00:00:26.960
如果他们使用词语的概率相同

00:00:26.960 --> 00:00:28.310
你就无法进行判断了

00:00:28.310 --> 00:00:32.384
如果他们使用词语的概率不同 他们可能使用其中之一

00:00:32.384 --> 00:00:33.814
100或1000

00:00:33.814 --> 00:00:38.224
但是你看到的每个词语 就像这里这个

00:00:38.224 --> 00:00:42.910
会为你提供证明是 A 或是 B 的证据

00:00:42.910 --> 00:00:47.410
而你要做的是 把你看到的每个词语的所有证据相乘

00:00:47.410 --> 00:00:50.230
这将是一个很大的乘积

00:00:50.230 --> 00:00:53.670
你分别对 A 和 B 进行了相应计算

00:00:53.670 --> 00:00:57.460
用相应的先验概率 当得出乘积时

00:00:57.460 --> 00:01:02.620
可以得到是否相信这个人是 A 或是 B 的概率

00:01:02.620 --> 00:01:04.300
这就叫做朴素贝叶斯

00:01:04.300 --> 00:01:10.050
它能让你从文本源中鉴别这个标签更有可能

00:01:10.050 --> 00:01:11.070
还是这个更有可能

00:01:11.070 --> 00:01:15.060
你可以使用这个方法判断人或新闻资源

00:01:15.060 --> 00:01:19.480
你可以问 比如这篇文章是莎士比亚还是其他人写的

00:01:20.640 --> 00:01:25.450
这是一个非常强大的工具 可以广泛地应用于机器学习领域

00:01:26.480 --> 00:01:28.050
之所以叫它朴素

00:01:29.600 --> 00:01:35.200
是因为它忽略了一件事 你能告诉我是哪件事吗？

00:01:35.200 --> 00:01:36.730
信息中每一个词语

00:01:37.990 --> 00:01:40.700
信息里词语的顺序

00:01:40.700 --> 00:01:42.600
还是信息的长度

00:01:42.600 --> 00:01:44.270
哪一个被朴素地忽略了呢？

