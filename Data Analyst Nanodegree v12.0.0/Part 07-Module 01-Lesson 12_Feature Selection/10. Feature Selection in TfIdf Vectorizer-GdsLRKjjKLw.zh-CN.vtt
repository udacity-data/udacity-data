WEBVTT
Kind: captions
Language: zh-CN

00:00:00.180 --> 00:00:02.150
现在我会更具体地来说一说

00:00:02.150 --> 00:00:03.670
让你更能明白我的意思

00:00:03.670 --> 00:00:07.670
我会向你演示一些代码示例

00:00:07.670 --> 00:00:10.640
其实你已经在本课中运行过了 虽然可能你并不知道

00:00:10.640 --> 00:00:12.040
回想我们一开始学习

00:00:12.040 --> 00:00:15.240
监督分类算法的课程

00:00:15.240 --> 00:00:18.410
我们试着分辨邮件的作者

00:00:18.410 --> 00:00:23.030
现在 我要让你关注朴素贝叶斯分类器或

00:00:23.030 --> 00:00:26.290
SVM 或类似的东西 让我来做预处理

00:00:26.290 --> 00:00:28.680
我会研究邮件

00:00:28.680 --> 00:00:31.420
把他们整理成合适你用的格式

00:00:31.420 --> 00:00:34.040
我要做的就是把你代入

00:00:34.040 --> 00:00:36.440
我在预处理步骤中实际使用的代码

00:00:36.440 --> 00:00:39.200
你可以发现真的没有什么魔法

00:00:39.200 --> 00:00:43.300
而以后你都需要完全靠你自己完成这些

00:00:43.300 --> 00:00:45.660
让我带你仔细注意代码 向你演示我是怎么做的

00:00:45.660 --> 00:00:46.780
所以我载入数据

00:00:46.780 --> 00:00:51.000
把它放入我的 TfidfVectorizer 现在你对它应该已经很熟悉了

00:00:51.000 --> 00:00:53.240
接着是下一步

00:00:53.240 --> 00:00:54.510
Select percentile

00:00:54.510 --> 00:00:57.380
我制作了一个选择器 然后选择了一个百分位数

00:00:57.380 --> 00:01:02.180
而这一步实际上就删除了很多特征

00:01:02.180 --> 00:01:03.570
我知道这个是文字数据

00:01:03.570 --> 00:01:06.450
里面有成千上万的特征

00:01:06.450 --> 00:01:09.770
因为我们有很大的词汇表

00:01:09.770 --> 00:01:14.010
我也知道这些单词可能是无关的单词

00:01:14.010 --> 00:01:16.340
比如说 停止词就是无关的词

00:01:16.340 --> 00:01:19.100
也有很多不属于停止词

00:01:19.100 --> 00:01:21.510
但是也不含有很多信息的词

00:01:21.510 --> 00:01:24.750
他们不能帮助我找出谁是作者

00:01:24.750 --> 00:01:29.440
所以在这一步中 我选择了一个百分位数

00:01:29.440 --> 00:01:32.500
实际上是删除了很多特征

00:01:32.500 --> 00:01:37.020
你认真研究每个特征 看看它们是否

00:01:37.020 --> 00:01:40.850
能够帮你很好地分辨两个人的邮件

00:01:40.850 --> 00:01:43.870
然后只接受最好的10%的特征

00:01:43.870 --> 00:01:45.630
用于我的分类器

00:01:45.630 --> 00:01:49.010
所以我这里是切掉了最表层的东西

00:01:49.010 --> 00:01:51.030
包含最多信息的特征

00:01:51.030 --> 00:01:54.220
然后专注于那些我用于分类器的东西

00:01:54.220 --> 00:01:58.240
然后我在其他地方也完成了特征缩减

00:01:58.240 --> 00:02:00.650
你可能不想要混淆这两个

00:02:00.650 --> 00:02:03.990
但是我希望你能自己来试试寻宝

00:02:03.990 --> 00:02:06.310
我之前告诉了你选择百分比数

00:02:06.310 --> 00:02:08.630
在 sklearn.feature_selection 模块下

00:02:08.630 --> 00:02:11.270
有我能用的一些东西

00:02:11.270 --> 00:02:14.480
在我进行数据的 TfidfVectorization 时

00:02:14.480 --> 00:02:18.300
在我实际将我语料库的单词

00:02:18.300 --> 00:02:21.240
放入 Tfidf 矩阵时

00:02:21.240 --> 00:02:23.480
我也可以完成一些特征选择

00:02:24.850 --> 00:02:29.120
我想要你看一看这个函数 TfidfVectorizer

00:02:29.120 --> 00:02:31.260
的文件

00:02:31.260 --> 00:02:33.810
然后看看我传递的参数

00:02:33.810 --> 00:02:36.450
其中一个参数有点意思

00:02:36.450 --> 00:02:38.930
就是说如果有个词出现得非常频繁

00:02:38.930 --> 00:02:41.330
而我们也想要无视它

00:02:41.330 --> 00:02:46.560
我说出现得非常频繁是指它出现在很多文件中

00:02:46.560 --> 00:02:50.850
比如说我有一个词出现在每一个文件中

00:02:50.850 --> 00:02:56.200
在你制作 Tfidf 时 这个参数会删除它

00:02:56.200 --> 00:02:57.950
好了 现在是有点棘手的测试题

00:02:57.950 --> 00:03:01.170
因为我还没有告诉你哪个参数有这个功能

00:03:01.170 --> 00:03:03.120
虽然你快速 Google 一下

00:03:03.120 --> 00:03:05.630
或者看看 sklearn 文件 就会非常清楚

00:03:05.630 --> 00:03:10.980
但我在测试中问你的问题是

00:03:10.980 --> 00:03:14.200
这个 Tfidf 无视某个单词的门槛是什么

00:03:14.200 --> 00:03:16.566
某个单词会在什么时候被抛弃呢

00:03:16.566 --> 00:03:20.960
当它出现在10%、50%还是90%的文件中？

