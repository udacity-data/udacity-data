WEBVTT
Kind: captions
Language: en

00:00:00.200 --> 00:00:03.570
Welcome to the lesson on Feature Selection.

00:00:03.570 --> 00:00:06.910
I think Albert Einstein probably said it best when he said you

00:00:06.910 --> 00:00:11.020
should make everything as simple as possible, but no simpler.

00:00:11.020 --> 00:00:14.070
This is the idea behind feature selection, that you want to have

00:00:14.070 --> 00:00:18.110
the minimal number of features that it takes to really capture the trends and

00:00:18.110 --> 00:00:19.760
the patterns in your data.

00:00:19.760 --> 00:00:23.210
Your machine learning algorithm is only going to be as good as the features that

00:00:23.210 --> 00:00:24.300
you put into it.

00:00:24.300 --> 00:00:26.910
So this is a place where you should really put some time and

00:00:26.910 --> 00:00:28.740
attention as a machine learner.

00:00:28.740 --> 00:00:31.900
There are two major things that are involved here.

00:00:31.900 --> 00:00:34.740
The first is that you should have a way to select the best features that

00:00:34.740 --> 00:00:36.130
are available to you.

00:00:36.130 --> 00:00:39.450
In other words getting rid of the stuff that doesn't help you very much.

00:00:39.450 --> 00:00:42.230
On the other hand there will be hopefully patterns in your data that you

00:00:42.230 --> 00:00:45.660
need to draw out, and so potentially adding new features can

00:00:45.660 --> 00:00:50.270
be ways that you can use your human intuition to access those patterns.

00:00:50.270 --> 00:00:52.400
We'll go through both of these examples in this lesson.

