WEBVTT
Kind: captions
Language: ar

00:00:00.180 --> 00:00:02.150
،حسنًا لكي نجعل الأمر ملموسًا بشكل أكبر

00:00:02.150 --> 00:00:03.670
.ما قد يساعد في فهم ما أعنيه

00:00:03.670 --> 00:00:07.670
سوف أعرض عليكم بعض الأمثلة الحقيقية من بعض التعليمات البرمجية التي

00:00:07.670 --> 00:00:10.640
.قمتم بتشغيلها بالفعل في هذا الدرس دون أية دراية من جانبكم بها

00:00:10.640 --> 00:00:12.040
فلتعيدوا التفكير في الدرسين الأول والثاني

00:00:12.040 --> 00:00:15.240
حيث تعلمنا خوارزميات التصنيف الخاضع للإشراف

00:00:15.240 --> 00:00:18.410
.وحاولنا تحديد رسائل البريد الإلكتروني حسب من كتبها

00:00:18.410 --> 00:00:23.030
الآن، ما أريده منكم هو التركيز على المصنف الأساسي naive أو

00:00:23.030 --> 00:00:26.290
.جهاز متجهات الدعم أو ما شابههما مع الاعتماد عليّ فيما يتعلق بالمعالجة المسبقة

00:00:26.290 --> 00:00:28.680
وسوف أهتم بشأن قراءة محتويات رسائل البريد الإلكتروني

00:00:28.680 --> 00:00:31.420
.ووضعها في تنسيق يكون ملائمًا لكم

00:00:31.420 --> 00:00:34.040
والآن سأنتقل بكم إلى التعليمة البرمجية التي

00:00:34.040 --> 00:00:36.440
،انتهيت من تنفيذ خطوة المعالجة المسبقة لها

00:00:36.440 --> 00:00:39.200
.بحيث تتمكنوا من معرفة أنه في الواقع لا يوجد سحر أسود هنا

00:00:39.200 --> 00:00:43.300
.وأنه يمكنكم إتمام ذلك بأنفسكم في المستقبل

00:00:43.300 --> 00:00:45.660
.دعوني أنتقل بكم إلى تلك التعليمة البرمجية وأريكم ما أفعل

00:00:45.660 --> 00:00:46.780
.سأقوم بتحميل البيانات

00:00:46.780 --> 00:00:51.000
.وأضعها في موجه TfidfVectorizer الخاص بي، والذي أنتم على دراية به حتى الآن

00:00:51.000 --> 00:00:53.240
،والآن ثمة خطوة أخرى هنا أيضًا

00:00:53.240 --> 00:00:54.510
.وهي تحديد القيمة المئوية

00:00:54.510 --> 00:00:57.380
.وقد اخترت المحدد والقيمة المئوية

00:00:57.380 --> 00:01:02.180
.فما تقوم به هذه الخطوة هو أنها تتخلص من الكثير من الميزات

00:01:02.180 --> 00:01:03.570
.أنا أعلم أن هذه بيانات نصية

00:01:03.570 --> 00:01:06.450
وأنها تحتوي على الآلاف أو ربما عشرات

00:01:06.450 --> 00:01:09.770
.الآلاف من الميزات نظرًا لعدد المصطلحات الكبير الذي نمتلكه

00:01:09.770 --> 00:01:14.010
.كما أنني أعرف أن الكثير من تلك الكلمات ليست ذات صلة

00:01:14.010 --> 00:01:16.340
.وتعد الكلمات المستبعدة من الفهرسة أحد الأمثلة على الكلمات التي ليست ذات صلة

00:01:16.340 --> 00:01:19.100
ولكن من المحتمل وجود الكثير من الكلمات التي لا تندرج ضمن قائمة الكلمات

00:01:19.100 --> 00:01:21.510
.المستبعدة من الفهرسة، ولكن لا تنطوي أيضًا على الكثير من المعلومات لتخبرنا بشأنها

00:01:21.510 --> 00:01:24.750
.فهي لن تساعدني في التفكير بشأن معرفة الكاتب بدقة تمامًا

00:01:24.750 --> 00:01:29.440
،إذن، ما فعلته في هذه الخطوة التي حددت خلالها قيمة مئوية

00:01:29.440 --> 00:01:32.500
.هو، كما قلت، أنني تخلصت من مجموعة من الميزات

00:01:32.500 --> 00:01:37.020
استمر في استكشاف كل ميزة على حدة ومعرفة مدى ملاءمة المهمة التي

00:01:37.020 --> 00:01:40.850
.تنفذها الميزة في إخبارك أن رسائل البريد الإلكتروني لشخصين اثنين منفصلتان عن بعضهما

00:01:40.850 --> 00:01:43.870
ولا تقبل سوى أفضل 10% من الميزات

00:01:43.870 --> 00:01:45.630
.بالنسبة لي لاستخدامها فيما بعد في المصنف

00:01:45.630 --> 00:01:49.010
.إذن، ما فعلته هنا هو استقطاع الجزء الموجود في قمة الطبقة العلوية

00:01:49.010 --> 00:01:51.030
.الميزات التي يبدو أنها تنطوي على أكثر المعلومات

00:01:51.030 --> 00:01:54.220
.وأنا أركز على تلك الميزات عند صنع المصنف الخاص بي

00:01:54.220 --> 00:01:58.240
.الآن ثمة موضع آخر حيث قللت أيضًا من بعض الميزات

00:01:58.240 --> 00:02:00.650
.وأنتم قد لا ترغبون دومًا في الخلط بينهما سويًا

00:02:00.650 --> 00:02:03.990
.ولكني أرغب في إرسالكم في رحلة قصيرة نحو البحث عن كنز ما

00:02:03.990 --> 00:02:06.310
.لقد أخبرتكم بشأن تحديد القيمة المئوية

00:02:06.310 --> 00:02:08.630
وهو الشيء المتاح لي في

00:02:08.630 --> 00:02:11.270
.وحدة sklearn.feature_selection

00:02:11.270 --> 00:02:14.480
ولكن يمكنني أيضًا تحديد بعض الميزات

00:02:14.480 --> 00:02:18.300
.عند تنفيذ عملية توجيه TfidfVectorization لبياناتي

00:02:18.300 --> 00:02:21.240
عندما أنقل الكلمات في المتن الخاص بي

00:02:21.240 --> 00:02:23.480
.وأضعها في مصفوفة Tfidf الخاصة بي

00:02:24.850 --> 00:02:29.120
إذن ما أطلب منكم فعله هو البحث في الوثائق عن هذه الدالة

00:02:29.120 --> 00:02:31.260
،TfidfVectorizer

00:02:31.260 --> 00:02:33.810
.ولتلقوا نظرة على الوسيطات التي مررت بها

00:02:33.810 --> 00:02:36.450
.وإحدى تلك الوسيطات تصنع بعض المتعة

00:02:36.450 --> 00:02:38.930
،وقد قيل إنه إذا كان ثمة كلمة تتكرر كثيرًا

00:02:38.930 --> 00:02:41.330
.فنحن سنرغب في تجاهلها أيضًا

00:02:41.330 --> 00:02:46.560
.وبمثل هذا التكرار الكبير، ما أعنيه أنها تتكرر في العديد من الوثائق

00:02:46.560 --> 00:02:50.850
لذا فعلى سبيل المثال، إذا كانت لديكم كلمة تتكرر في كل وثيقة، فثمة

00:02:50.850 --> 00:02:56.200
.وسيطة هنا سوف تعمل على التخلص منها بالتأكيد عند صنع مصفوفة Tfidf الخاصة بك

00:02:56.200 --> 00:02:57.950
،حسنًا، هذا اختبار خادع قليلاً

00:02:57.950 --> 00:03:01.170
.نظرًا لأنني لم أخبرك تمامًا أي الوسيطات التي تنفذ ذلك الأمر

00:03:01.170 --> 00:03:03.120
وبالرغم من أن استخدام Google في إجراء بحث

00:03:03.120 --> 00:03:05.630
.سريع والاطلاع على وثائق sklearn من المفترض أن يوضحا الأمر بشكل كبير

00:03:05.630 --> 00:03:10.980
،ولكن السؤال الذي سأطرحه عليك في الاختبار سيرتبط بماهية هذا الحد

00:03:10.980 --> 00:03:14.200
.والمرتبط بمصفوفة Tfidf الخاصة هذه لتجاهل الكلمة

00:03:14.200 --> 00:03:16.566
إذن، هل يتم تجاهل الكلمة إذا

00:03:16.566 --> 00:03:20.960
كانت قيمة تكرارها تبلغ 10% من الوثائق أم 50% أم 90%؟

